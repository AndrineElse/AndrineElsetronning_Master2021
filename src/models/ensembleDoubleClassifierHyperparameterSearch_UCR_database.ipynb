{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "italian-craft",
   "metadata": {},
   "source": [
    "# Hyperparameter search for double classification task\n",
    "\n",
    "The purpose of this notebook is to search for the optimal hyperparameters for each classifier involved. \n",
    "\n",
    "A dictionary (dict_classifiers) is written to 'classifier_dict.pkl', so that it can be used later on, for testing. \n",
    "This hyperparameter search is done to avoid having to do a exhaustive search for hyperparameters during testing / development. \n",
    "\n",
    "For each dataset the following classifiers are saved: \n",
    "\n",
    "* An initial classifier ( KNN, LR, RF, SVM), that is trained on the entire training set, from the original partition ( 0.8 train, 0.2 test)\n",
    "* An ensemble of n = 5 classifiers (KNN, LR, RF, SVM), that is trained for the secondary classification task, on a k-fold = 5, part of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sealed-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifiers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fifteen-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "sys.path.insert(1, module_path + '/src/')\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning, DataConversionWarning, FitFailedWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FitFailedWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sktime.utils.data_io import load_from_arff_to_dataframe\n",
    "import time\n",
    "\n",
    "\n",
    "import utility\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "font = FontProperties(fname = module_path + '/src/visualization/CharterRegular.ttf', size = 10, weight = 1000)\n",
    "font_small = FontProperties(fname = module_path + '/src/visualization/CharterRegular.ttf', size = 8, weight = 1000)\n",
    "\n",
    "\n",
    "from sktime.datasets import load_UCR_UEA_dataset\n",
    "from sktime.transformations.panel.catch22_features import Catch22\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset_partitions(X, y, ft):\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "    norm = MinMaxScaler()\n",
    "    X_train_full = pd.DataFrame(norm.fit_transform(X_train_full))\n",
    "    X_test = pd.DataFrame(norm.fit_transform(X_test))\n",
    "    k = min([X_test.shape[0], 100])\n",
    "    print('Chosen number of components: ', k)\n",
    "    '''\n",
    "    if (ft == 'rocket') and (fs == 'pca'):  \n",
    "        pca = PCA(n_components = k)\n",
    "        X_train_full = pca.fit_transform(X_train_full)\n",
    "        X_train_full = pd.DataFrame(X_train_full)\n",
    "        \n",
    "        X_test = pca.fit_transform(X_test)\n",
    "        X_test = pd.DataFrame(X_test)\n",
    "    '''\n",
    "    if (ft == 'rocket'):\n",
    "        select = SelectKBest(chi2, k=k)\n",
    "        X_train_full = select.fit_transform(X_train_full, y_train_full)\n",
    "        indices = select.get_support(indices = True)\n",
    "        X_test = X_test[indices]\n",
    "    return pd.DataFrame(X_train_full), y_train_full, pd.DataFrame(X_test), y_test\n",
    "\n",
    "\n",
    "def get_initial_classifier(X_train_full,y_train_full, clf, grid, no_grid_search = False):\n",
    "    grid_cv=GridSearchCV(clf,grid,cv=5)\n",
    "    grid_cv.fit(X_train_full,y_train_full)\n",
    "    return grid_cv.best_estimator_\n",
    "\n",
    "def get_helping_classifier(X_train, y_train, X_val, y_val, clf, grid ):\n",
    "    '''Get the helping classifier\n",
    "    \n",
    "    returns a classifier, which classifies if something is likely to be classified wrongly\n",
    "    \n",
    "    '''\n",
    "    new_X = X_val\n",
    "\n",
    "    #grid_cv=GridSearchCV(clf,grid,cv=5)\n",
    "    #grid_cv.fit(X_train,y_train)\n",
    "    #clf_2 = grid_cv.best_estimator_\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    new_y = pd.Series(np.hstack([y_pred != y_val]))\n",
    "    clf = LogisticRegression(random_state=0, solver = 'liblinear',penalty = 'l1', class_weight = 'balanced').fit(new_X,new_y)\n",
    "    return clf\n",
    "'''   \n",
    "    grid_cv=GridSearchCV(clf,grid,cv=5)\n",
    "    if 'True' not in list(new_y.astype(str)):\n",
    "         return None, None\n",
    "    grid_cv.fit(new_X,new_y)\n",
    "    return grid_cv.best_estimator_ , grid_cv.best_score_\n",
    "'''\n",
    "\n",
    "def get_ensemble_helping_classifier(X_train, y_train, clf, grid):\n",
    "    kf = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "    #kf.get_n_splits(X_train)\n",
    "    classifiers = []\n",
    "    for train_index, val_index in kf.split(X_train, y_train):\n",
    "        #clf_temp, score_temp = get_helping_classifier(X_train.iloc[train_index], y_train.iloc[train_index], X_train.iloc[val_index], y_train.iloc[val_index], clf, grid)\n",
    "        clf_temp = get_helping_classifier(X_train.iloc[train_index], y_train.iloc[train_index], X_train.iloc[val_index], y_train.iloc[val_index], clf, grid)\n",
    "        if clf_temp == None:\n",
    "            continue\n",
    "        #classifiers.append((clf_temp, score_temp))\n",
    "        classifiers.append(clf_temp)\n",
    "    return classifiers\n",
    "\n",
    "def make_ensemble_classification(X_test, ensemble):\n",
    "    y_pred = []\n",
    "    for e in ensemble: \n",
    "        clf = e[0]\n",
    "        score = e[1]\n",
    "        y_pred_temp = clf.predict(X_test)\n",
    "        y_pred.append((score * (y_pred_temp + 1)) -1)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_sum = y_pred.sum(axis = 0)\n",
    "    idx_true = np.where(y_pred_sum > 0)[0]\n",
    "    \n",
    "    y_pred = y_pred.mean(axis = 0)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    \n",
    "    y_pred[idx_true] = 1\n",
    "    return y_pred\n",
    "\n",
    "def make_ensemble_classification_2(X_test, ensemble):\n",
    "    y_pred = []\n",
    "    for clf in ensemble: \n",
    "        y_pred_temp = clf.predict(X_test).astype(int)\n",
    "        y_pred.append(y_pred_temp)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_sum = y_pred.sum(axis = 0)\n",
    "    idx_true = np.where(y_pred_sum >= 1)[0]\n",
    "    \n",
    "    y_pred = np.zeros(y_pred_temp.shape)\n",
    "\n",
    "    \n",
    "    y_pred[idx_true] = 1\n",
    "    return y_pred\n",
    "\n",
    "def filter_test_set_ensemble(X_test, y_test, ensemble):\n",
    "    y_pred = make_ensemble_classification_2(X_test, ensemble)\n",
    "    to_del = np.where(y_pred == 1)[0]\n",
    "    print('Indices to delete: ')\n",
    "    print(to_del)\n",
    "    X_test = X_test.reset_index(drop = True)\n",
    "    y_test = y_test.reset_index(drop = True)\n",
    "    X_test_new = X_test[~X_test.index.isin(to_del)]\n",
    "    y_test_new = y_test[~y_test.index.isin(to_del)]\n",
    "    return X_test_new, y_test_new\n",
    "\n",
    "\n",
    "def plot_cm(clf, X_test, y_test, class_names, color_index = 2):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    colors = [\"#F94144\", \"#F3722C\", '#F8961E', '#F9C74F','#90BE6D', '#43AA8B','#577590']\n",
    "\n",
    "    font = FontProperties(fname = module_path + '/src/visualization/CharterRegular.ttf', size = 10, weight = 1000)\n",
    "\n",
    "    colors_2 = ['#FFFFFF', colors[color_index]]\n",
    "    cmap_name = 'my colormap'\n",
    "    font_small = FontProperties(fname =  module_path + '/src/visualization/CharterRegular.ttf', size = 6, weight = 1000)\n",
    "\n",
    "    cm_map = LinearSegmentedColormap.from_list(cmap_name, colors_2)\n",
    "\n",
    "\n",
    "    f, ax = plt.subplots(1,1) # 1 x 1 array , can also be any other size\n",
    "    f.set_size_inches(5, 5)\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    ax = sns.heatmap(cm, annot=True,\n",
    "                fmt='.2%', cmap=cm_map, xticklabels=class_names,yticklabels=class_names )\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    for label in ax.get_yticklabels() :\n",
    "        label.set_fontproperties(font_small)\n",
    "    for label in ax.get_xticklabels() :\n",
    "        label.set_fontproperties(font_small)\n",
    "    ax.set_ylabel('True Label', fontproperties = font)\n",
    "    ax.set_xlabel('Predicted Label', fontproperties = font)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 0)\n",
    "\n",
    "    for child in ax.get_children():\n",
    "        if isinstance(child, matplotlib.text.Text):\n",
    "            child.set_fontproperties(font)\n",
    "    for l in cbar.ax.yaxis.get_ticklabels():\n",
    "        l.set_fontproperties(font_small)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_and_plot_to_compare(X_test, y_test, X_test_2, y_test_2, clf, class_names):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc_1 = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy score for the initial classification: {acc_1} ')\n",
    "    plot_cm(clf, X_test, y_test, class_names)\n",
    "    \n",
    "    y_pred_2 = clf.predict(X_test_2)\n",
    "    acc_2 = accuracy_score(y_test_2, y_pred_2)\n",
    "    print(f'Accuracy score for the double classification: {acc_2} ')\n",
    "    plot_cm(clf, X_test_2, y_test_2, class_names, color_index = 5)\n",
    "    return acc_1 , acc_2\n",
    "    \n",
    "def compare_single_double_classifier(name_UCR, class_names, feature_transform = 'rocket'):\n",
    "    a_file = open(module_path + '/src/dictionaries/empty_temp_dict.pkl', 'rb')\n",
    "    temp_dict = pickle.load(a_file)\n",
    "\n",
    "    X, y = load_UCR_UEA_dataset(name_UCR, return_X_y=True)\n",
    "  \n",
    "    if (feature_transform == 'rocket'):\n",
    "        rocket = Rocket(random_state=1)  # by default, ROCKET uses 10,000 kernels\n",
    "        rocket.fit(X)\n",
    "        X = rocket.transform(X)\n",
    "    else:\n",
    "        c22f = Catch22()\n",
    "        c22f.fit(X, y)\n",
    "        X = c22f.transform(X)\n",
    "\n",
    "    X_train_full, y_train_full , X_test, y_test = get_dataset_partitions(X,y, feature_transform)\n",
    "    \n",
    "    ############ K nearest neighbours \n",
    "    max_nn = round((0.8*X.shape[0])//8)\n",
    "    k_range = list(range(1,max_nn))\n",
    "    weight_options = [\"uniform\", \"distance\"]\n",
    "    grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "    clf = KNeighborsClassifier()\n",
    "    \n",
    "    clf_full = get_initial_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['KNN']['init'] = clf_full\n",
    "    clf_ensemble = get_ensemble_helping_classifier(X_train_full, y_train_full, clf_full, grid)\n",
    "    temp_dict['KNN']['ensemble'] = clf_ensemble\n",
    "\n",
    "    ############ Logistic Regression\n",
    "    grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\"]}\n",
    "    clf=LogisticRegression()\n",
    "\n",
    "    clf_full = get_initial_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['LR']['init'] = clf_full\n",
    "    clf_ensemble = get_ensemble_helping_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['LR']['ensemble'] = clf_ensemble\n",
    "\n",
    "  \n",
    "    ############ SVM\n",
    "    grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf']}  \n",
    "    clf = SVC()\n",
    "\n",
    "    clf_full = get_initial_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['SVM']['init'] = clf_full\n",
    "    clf_ensemble = get_ensemble_helping_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['SVM']['ensemble'] = clf_ensemble\n",
    "\n",
    "    ############# Random Forest\n",
    "    grid = {\n",
    "    'n_estimators'      : [100,200,300],\n",
    "    'max_depth'         : [8, 10, 12],\n",
    "    'random_state'      : [0],\n",
    "    }\n",
    "    clf = RandomForestClassifier()\n",
    "\n",
    "    clf_full = get_initial_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['RF']['init'] = clf_full\n",
    "    clf_ensemble = get_ensemble_helping_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['RF']['ensemble'] = clf_ensemble\n",
    "    return temp_dict\n",
    "\n",
    "def convert_arff_to_ts(filepath, filename):\n",
    "    X, y = load_from_arff_to_dataframe(filepath + '/' + filename)\n",
    "    new_filename = filename[:-4] + 'ts'\n",
    "    print(new_filename)\n",
    "    dataset = filename.split('_')[0]\n",
    "    print(dataset)\n",
    "    \n",
    "    labels = np.unique(y).astype(str)\n",
    "    label_str = ''\n",
    "    for label in labels:\n",
    "        label_str = label_str + label + ' '\n",
    "    print(label_str)\n",
    "    w = open(filepath + '/' + new_filename, 'w+')\n",
    "    \n",
    "    w.write(f'@problemName {dataset} \\n')\n",
    "    w.write('@timeStamps false \\n')\n",
    "    w.write('@univariate true \\n')\n",
    "    w.write(f'@classLabel true {label_str} \\n')\n",
    "    w.write('@data \\n')\n",
    "    for (idx, row) in X.iterrows():\n",
    "        new_row = (list(row)[0]).tolist()\n",
    "        new_row = str(new_row)[1:-1].replace(' ', '') + ':' + y[idx] + '\\n'\n",
    "        w.write(new_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-tampa",
   "metadata": {},
   "source": [
    "# Arrowhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "standard-atlantic",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen number of components:  43\n",
      "Time used to find hyperparameters: 24.61294937133789\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Avonlea', 'Clovis','Mix']\n",
    "name_UCR = 'ArrowHead'\n",
    "\n",
    "start = time.time()\n",
    "dict_classifiers[name_UCR]= compare_single_double_classifier(name_UCR, class_names)\n",
    "print(f'Time used to find hyperparameters: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-franchise",
   "metadata": {},
   "source": [
    "# Osuleaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fluid-sympathy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen number of components:  89\n",
      "Time used to find hyperparameters: 42.38264441490173\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Acer Circinatum', 'Acer Glabrum', 'Acer Macrophyllum', 'Acer Negundo', 'Quercus Garryanaand' , 'Quercus Kelloggii' ]\n",
    "name_UCR = 'OSULeaf'\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "dict_classifiers[name_UCR]= compare_single_double_classifier(name_UCR, class_names)\n",
    "print(f'Time used to find hyperparameters: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-shopper",
   "metadata": {},
   "source": [
    "# ECG 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "southwest-utilization",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen number of components:  40\n",
      "Time used to find hyperparameters: 24.800294637680054\n"
     ]
    }
   ],
   "source": [
    "class_names = ['normal','myocardial']\n",
    "name_UCR = 'ECG200'\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "dict_classifiers[name_UCR]= compare_single_double_classifier(name_UCR, class_names)\n",
    "print(f'Time used to find hyperparameters: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-swaziland",
   "metadata": {},
   "source": [
    "# ChlorineConsentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "charitable-medicare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen number of components:  100\n",
      "Time used to find hyperparameters: 2391.799001932144\n"
     ]
    }
   ],
   "source": [
    "class_names = ['0', '1', '2']\n",
    "name_UCR = 'ChlorineConcentration'\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "dict_classifiers[name_UCR]= compare_single_double_classifier(name_UCR, class_names)\n",
    "print(f'Time used to find hyperparameters: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-radical",
   "metadata": {},
   "source": [
    "# PhalangesOutlinesCorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "signed-detection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen number of components:  100\n",
      "Time used to find hyperparameters: 530.091997385025\n"
     ]
    }
   ],
   "source": [
    "class_names = ['0', '1']\n",
    "name_UCR = 'PhalangesOutlinesCorrect'\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "dict_classifiers[name_UCR]= compare_single_double_classifier(name_UCR, class_names)\n",
    "print(f'Time used to find hyperparameters: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-conversation",
   "metadata": {},
   "source": [
    "# DistalPhalanxOutlineCorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "committed-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen number of components:  100\n",
      "Time used to find hyperparameters: 70.74565196037292\n"
     ]
    }
   ],
   "source": [
    "class_names = ['0', '1']\n",
    "name_UCR = 'DistalPhalanxOutlineCorrect'\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "dict_classifiers[name_UCR]= compare_single_double_classifier(name_UCR, class_names)\n",
    "print(f'Time used to find hyperparameters: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-prerequisite",
   "metadata": {},
   "source": [
    "# CricketZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "champion-tuition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen number of components:  100\n",
      "Time used to find hyperparameters: 107.69919204711914\n"
     ]
    }
   ],
   "source": [
    "n_classes = 12\n",
    "class_names = np.linspace(0,n_classes -1 ,n_classes).astype(int).astype(str).tolist()\n",
    "\n",
    "name_UCR = 'CricketZ'\n",
    "\n",
    "start = time.time()\n",
    "dict_classifiers[name_UCR]= compare_single_double_classifier(name_UCR, class_names)\n",
    "print(f'Time used to find hyperparameters: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-chicken",
   "metadata": {},
   "source": [
    "# ERing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "charged-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen number of components:  60\n",
      "Time used to find hyperparameters: 31.55928325653076\n"
     ]
    }
   ],
   "source": [
    "n_classes = 6\n",
    "class_names = np.linspace(0,n_classes -1 ,n_classes).astype(int).astype(str).tolist()\n",
    "\n",
    "name_UCR = 'ERing'\n",
    "\n",
    "start = time.time()\n",
    "dict_classifiers[name_UCR]= compare_single_double_classifier(name_UCR, class_names)\n",
    "print(f'Time used to find hyperparameters: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-comparative",
   "metadata": {},
   "source": [
    "# Colposcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "crazy-funeral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colposcopy_TEST.ts\n",
      "Colposcopy\n",
      "0 1 2 3 4 5 \n",
      "Chosen number of components:  40\n",
      "Time used to find hyperparameters: 24.2416570186615\n"
     ]
    }
   ],
   "source": [
    "filepath = '/home/andrine/anaconda3/lib/python3.7/site-packages/sktime/datasets/data/Colposcopy'\n",
    "filename  = 'Colposcopy_TEST.arff'\n",
    "convert_arff_to_ts(filepath, filename)\n",
    "\n",
    "n_classes = 6\n",
    "class_names = np.linspace(0,n_classes -1 ,n_classes).astype(int).astype(str).tolist()\n",
    "\n",
    "name_UCR = 'Colposcopy'\n",
    "\n",
    "start = time.time()\n",
    "dict_classifiers[name_UCR]= compare_single_double_classifier(name_UCR, class_names)\n",
    "print(f'Time used to find hyperparameters: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-precipitation",
   "metadata": {},
   "source": [
    "# Epilepsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "median-buying",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen number of components:  55\n",
      "Time used to find hyperparameters: 31.684996366500854\n"
     ]
    }
   ],
   "source": [
    "n_classes = 4\n",
    "class_names = np.linspace(0,n_classes -1 ,n_classes).astype(int).astype(str).tolist()\n",
    "\n",
    "name_UCR = 'Epilepsy'\n",
    "\n",
    "start = time.time()\n",
    "dict_classifiers[name_UCR]= compare_single_double_classifier(name_UCR, class_names)\n",
    "print(f'Time used to find hyperparameters: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-absolute",
   "metadata": {},
   "source": [
    "# EyesOpenShut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "empty-saying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EyesOpenShut_TEST.ts\n",
      "EyesOpenShut\n",
      "0 1 \n",
      "EyesOpenShut_TRAIN.ts\n",
      "EyesOpenShut\n",
      "0 1 \n",
      "Chosen number of components:  20\n",
      "Time used to find hyperparameters: 18.894746780395508\n"
     ]
    }
   ],
   "source": [
    "name_UCR = 'EyesOpenShut'\n",
    "\n",
    "# Code below is to fix the issue that this dataset does not have .ts files yet \n",
    "filepath = f'/home/andrine/anaconda3/lib/python3.7/site-packages/sktime/datasets/data/{name_UCR}'\n",
    "filename  = f'{name_UCR}_TEST.arff'\n",
    "convert_arff_to_ts(filepath, filename)\n",
    "filename  = f'{name_UCR}_TRAIN.arff'\n",
    "convert_arff_to_ts(filepath, filename)\n",
    "n_classes = 2\n",
    "class_names = np.linspace(0,n_classes -1 ,n_classes).astype(int).astype(str).tolist()\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "dict_classifiers[name_UCR]= compare_single_double_classifier(name_UCR, class_names)\n",
    "print(f'Time used to find hyperparameters: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-strike",
   "metadata": {},
   "source": [
    "# FingerMovements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "agricultural-programming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen number of components:  84\n",
      "Time used to find hyperparameters: 40.28056812286377\n"
     ]
    }
   ],
   "source": [
    "name_UCR = 'FingerMovements'\n",
    "\n",
    "n_classes = 2\n",
    "class_names = np.linspace(0,n_classes -1 ,n_classes).astype(int).astype(str).tolist()\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "dict_classifiers[name_UCR]= compare_single_double_classifier(name_UCR, class_names)\n",
    "print(f'Time used to find hyperparameters: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-software",
   "metadata": {},
   "source": [
    "### Will not run on the following datasets \n",
    "\n",
    "Because of the computational effort of using catch22/ROCKET for feature extraction, the following time series problems will not run/ takes forever to run: \n",
    "\n",
    "* Electric Devices\n",
    "* Face Detection\n",
    "* ECG5000\n",
    "\n",
    "ECGFiveDays is too accurate already\n",
    "\n",
    "\n",
    "Maybe try out ROCKET instead "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-brown",
   "metadata": {},
   "source": [
    "# Lung Sound Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fixed-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_single_double_classifier_LS():    \n",
    "    a_file = open(module_path + '/src/dictionaries/empty_temp_dict.pkl', 'rb')\n",
    "    temp_dict = pickle.load(a_file)\n",
    "    \n",
    "    class_names = ['crackle', 'no-crackle']\n",
    "    X, y =  utility.get_X_y('noDecomp', feature_type = 'all')\n",
    "    X_train_full, y_train_full, X_test, y_test = get_dataset_partitions(X,y,'lungsound')\n",
    "\n",
    "    ############ K nearest neighbours \n",
    "    max_nn = round((0.8*X.shape[0])//8)\n",
    "    k_range = list(range(1,max_nn))\n",
    "    weight_options = [\"uniform\", \"distance\"]\n",
    "    grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "    clf = KNeighborsClassifier()\n",
    "    \n",
    "    clf_full = get_initial_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['KNN']['init'] = clf_full\n",
    "    clf_ensemble = get_ensemble_helping_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['KNN']['ensemble'] = clf_ensemble\n",
    "\n",
    "    ############ Logistic Regression\n",
    "    grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\"]}\n",
    "    clf=LogisticRegression()\n",
    "\n",
    "    clf_full = get_initial_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['LR']['init'] = clf_full\n",
    "    clf_ensemble = get_ensemble_helping_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['LR']['ensemble'] = clf_ensemble\n",
    "\n",
    "  \n",
    "    ############ SVM\n",
    "    grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf']}  \n",
    "    clf = SVC()\n",
    "\n",
    "    clf_full = get_initial_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['SVM']['init'] = clf_full\n",
    "    clf_ensemble = get_ensemble_helping_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['SVM']['ensemble'] = clf_ensemble\n",
    "\n",
    "    ############# Random Forest\n",
    "    grid = {\n",
    "    'n_estimators'      : [100,200,300],\n",
    "    'max_depth'         : [8, 10, 12],\n",
    "    'random_state'      : [0],\n",
    "    }\n",
    "    clf = RandomForestClassifier()\n",
    "\n",
    "    clf_full = get_initial_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['RF']['init'] = clf_full\n",
    "    clf_ensemble = get_ensemble_helping_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    temp_dict['RF']['ensemble'] = clf_ensemble\n",
    " \n",
    "\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ultimate-namibia",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen number of components:  100\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'builtin_function_or_method' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-e776aded6a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdict_classifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LungSound'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_single_double_classifier_LS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Time used to find hyperparameters: {time.time - start}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'builtin_function_or_method' and 'float'"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dict_classifiers['LungSound'] = compare_single_double_classifier_LS()\n",
    "print(f'Time used to find hyperparameters: {time.time() - start} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-vienna",
   "metadata": {},
   "source": [
    "## Write classifiers with found hyper-parameters to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forbidden-yellow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FingerMovements': {'SVM': {'init': SVC(C=10, gamma=1),\n",
       "   'ensemble': [(SVC(C=0.1, gamma=1), 0.5857707509881422),\n",
       "    (SVC(C=0.1, gamma=1), 0.6577075098814229),\n",
       "    (SVC(C=0.1, gamma=1), 0.6454545454545454)]},\n",
       "  'LR': {'init': LogisticRegression(C=0.1),\n",
       "   'ensemble': [(LogisticRegression(C=0.001), 0.5857707509881422),\n",
       "    (LogisticRegression(C=0.001), 0.6035573122529644),\n",
       "    (LogisticRegression(), 0.6181818181818182)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=8, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=10, n_estimators=200, random_state=0),\n",
       "     0.5411067193675889),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.6221343873517787),\n",
       "    (RandomForestClassifier(max_depth=10, n_estimators=200, random_state=0),\n",
       "     0.6)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=15),\n",
       "   'ensemble': [(KNeighborsClassifier(n_neighbors=21), 0.5857707509881422),\n",
       "    (KNeighborsClassifier(n_neighbors=19), 0.667193675889328),\n",
       "    (KNeighborsClassifier(n_neighbors=18, weights='distance'),\n",
       "     0.6545454545454545)]}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fallen-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(module_path + '/src/dictionaries/classifier_dict.pkl', 'rb')\n",
    "dict_classifiers_2 = pickle.load(a_file)\n",
    "joined = {**dict_classifiers, **dict_classifiers_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "affiliated-cleaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FingerMovements': {'SVM': {'init': SVC(C=10, gamma=1),\n",
       "   'ensemble': [(SVC(C=0.1, gamma=1), 0.5857707509881422),\n",
       "    (SVC(C=0.1, gamma=1), 0.6577075098814229),\n",
       "    (SVC(C=0.1, gamma=1), 0.6454545454545454)]},\n",
       "  'LR': {'init': LogisticRegression(C=0.1),\n",
       "   'ensemble': [(LogisticRegression(C=0.001), 0.5857707509881422),\n",
       "    (LogisticRegression(C=0.001), 0.6035573122529644),\n",
       "    (LogisticRegression(), 0.6181818181818182)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=8, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=10, n_estimators=200, random_state=0),\n",
       "     0.5411067193675889),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.6221343873517787),\n",
       "    (RandomForestClassifier(max_depth=10, n_estimators=200, random_state=0),\n",
       "     0.6)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=15),\n",
       "   'ensemble': [(KNeighborsClassifier(n_neighbors=21), 0.5857707509881422),\n",
       "    (KNeighborsClassifier(n_neighbors=19), 0.667193675889328),\n",
       "    (KNeighborsClassifier(n_neighbors=18, weights='distance'),\n",
       "     0.6545454545454545)]}},\n",
       " 'EyesOpenShut': {'SVM': {'init': SVC(C=1, gamma=1),\n",
       "   'ensemble': [(SVC(C=0.1, gamma=1), 0.6533333333333334),\n",
       "    (SVC(C=100, gamma=0.1), 0.54),\n",
       "    (SVC(C=1, gamma=1), 0.5866666666666667)]},\n",
       "  'LR': {'init': LogisticRegression(C=0.1),\n",
       "   'ensemble': [(LogisticRegression(C=1000.0), 0.7666666666666666),\n",
       "    (LogisticRegression(C=0.001), 0.5800000000000001),\n",
       "    (LogisticRegression(C=0.001), 0.5800000000000001)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=10, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=8, n_estimators=200, random_state=0),\n",
       "     0.5066666666666666),\n",
       "    (RandomForestClassifier(max_depth=8, n_estimators=300, random_state=0),\n",
       "     0.5066666666666666),\n",
       "    (RandomForestClassifier(max_depth=8, n_estimators=200, random_state=0),\n",
       "     0.6266666666666667)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(weights='distance'),\n",
       "   'ensemble': [(KNeighborsClassifier(n_neighbors=6), 0.5),\n",
       "    (KNeighborsClassifier(n_neighbors=6), 0.6466666666666667),\n",
       "    (KNeighborsClassifier(n_neighbors=3), 0.5)]}},\n",
       " 'Epilepsy': {'SVM': {'init': SVC(C=10, gamma=0.1),\n",
       "   'ensemble': [(SVC(C=0.1, gamma=1), nan),\n",
       "    (SVC(C=10, gamma=1), 0.9866666666666667)]},\n",
       "  'LR': {'init': LogisticRegression(C=100.0),\n",
       "   'ensemble': [(LogisticRegression(C=0.001), nan),\n",
       "    (LogisticRegression(C=100.0), 0.9866666666666667)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=8, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=8, random_state=0),\n",
       "     0.9733333333333334),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.9866666666666667),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0),\n",
       "     0.9314285714285715)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=1),\n",
       "   'ensemble': [(KNeighborsClassifier(n_neighbors=1), 0.9866666666666667),\n",
       "    (KNeighborsClassifier(n_neighbors=1), 0.9866666666666667),\n",
       "    (KNeighborsClassifier(n_neighbors=2), 0.9866666666666667)]}},\n",
       " 'Colposcopy': {'SVM': {'init': SVC(C=1, gamma=1),\n",
       "   'ensemble': [(SVC(C=100, gamma=0.01), 0.6571428571428571),\n",
       "    (SVC(C=100, gamma=0.1), 0.7190476190476189),\n",
       "    (SVC(C=1000, gamma=0.1), 0.6285714285714286),\n",
       "    (SVC(C=0.1, gamma=1), 0.7190476190476189),\n",
       "    (SVC(C=1000, gamma=0.01), 0.7285714285714286)]},\n",
       "  'LR': {'init': LogisticRegression(C=0.1),\n",
       "   'ensemble': [(LogisticRegression(C=10.0), 0.6857142857142857),\n",
       "    (LogisticRegression(C=0.001), 0.657142857142857),\n",
       "    (LogisticRegression(C=0.001), 0.5285714285714286),\n",
       "    (LogisticRegression(C=0.001), 0.6857142857142857),\n",
       "    (LogisticRegression(C=1000.0), 0.6)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=12, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=8, random_state=0),\n",
       "     0.638095238095238),\n",
       "    (RandomForestClassifier(max_depth=8, n_estimators=200, random_state=0),\n",
       "     0.5095238095238095),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.661904761904762),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.5619047619047619),\n",
       "    (RandomForestClassifier(max_depth=8, n_estimators=200, random_state=0),\n",
       "     0.5999999999999999)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=17, weights='distance'),\n",
       "   'ensemble': [(KNeighborsClassifier(), 0.6523809523809524),\n",
       "    (KNeighborsClassifier(), 0.5952380952380952),\n",
       "    (KNeighborsClassifier(n_neighbors=9), 0.657142857142857),\n",
       "    (KNeighborsClassifier(n_neighbors=17), 0.6285714285714284),\n",
       "    (KNeighborsClassifier(n_neighbors=6), 0.5952380952380952)]}},\n",
       " 'ArrowHead': {'SVM': {'init': SVC(C=100, gamma=0.1),\n",
       "   'ensemble': [(SVC(C=0.1, gamma=1), 0.8857142857142858),\n",
       "    (SVC(C=100, gamma=0.01), 0.9428571428571428),\n",
       "    (SVC(C=0.1, gamma=1), 0.8523809523809524),\n",
       "    (SVC(C=0.1, gamma=1), 0.8476190476190476),\n",
       "    (SVC(C=0.1, gamma=1), 0.9142857142857143)]},\n",
       "  'LR': {'init': LogisticRegression(C=100.0),\n",
       "   'ensemble': [(LogisticRegression(C=0.001), 0.8857142857142858),\n",
       "    (LogisticRegression(C=0.001), 0.8857142857142858),\n",
       "    (LogisticRegression(C=10.0), 0.9142857142857143),\n",
       "    (LogisticRegression(C=0.001), 0.8809523809523808),\n",
       "    (LogisticRegression(C=0.001), 0.9142857142857143)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=8, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=8, random_state=0),\n",
       "     0.8857142857142858),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.9142857142857143),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.8523809523809524),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.7904761904761906),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0),\n",
       "     0.9428571428571428)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=1),\n",
       "   'ensemble': [(KNeighborsClassifier(n_neighbors=2), 0.8523809523809524),\n",
       "    (KNeighborsClassifier(n_neighbors=1), 0.9142857142857143),\n",
       "    (KNeighborsClassifier(n_neighbors=4), 0.8523809523809524),\n",
       "    (KNeighborsClassifier(n_neighbors=1), 0.9095238095238095),\n",
       "    (KNeighborsClassifier(n_neighbors=1), 0.9666666666666668)]}},\n",
       " 'OSULeaf': {'SVM': {'init': SVC(C=1000, gamma=0.1),\n",
       "   'ensemble': [(SVC(C=0.1, gamma=1), 0.7180952380952381),\n",
       "    (SVC(C=0.1, gamma=1), 0.7323809523809525),\n",
       "    (SVC(C=100, gamma=0.1), 0.7038095238095238),\n",
       "    (SVC(C=0.1, gamma=1), 0.6714285714285715),\n",
       "    (SVC(C=0.1, gamma=1), 0.7142857142857143)]},\n",
       "  'LR': {'init': LogisticRegression(C=100.0),\n",
       "   'ensemble': [(LogisticRegression(C=0.001), 0.7885714285714285),\n",
       "    (LogisticRegression(C=0.001), 0.7047619047619048),\n",
       "    (LogisticRegression(C=10.0), 0.6057142857142856),\n",
       "    (LogisticRegression(C=0.001), 0.7714285714285715),\n",
       "    (LogisticRegression(C=0.001), 0.7142857142857143)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=12, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=8, random_state=0),\n",
       "     0.5476190476190477),\n",
       "    (RandomForestClassifier(max_depth=10, random_state=0), 0.6619047619047619),\n",
       "    (RandomForestClassifier(max_depth=8, n_estimators=300, random_state=0),\n",
       "     0.6323809523809524),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.6571428571428571),\n",
       "    (RandomForestClassifier(max_depth=8, n_estimators=200, random_state=0),\n",
       "     0.7000000000000001)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=4, weights='distance'),\n",
       "   'ensemble': [(KNeighborsClassifier(n_neighbors=24, weights='distance'),\n",
       "     0.6352380952380953),\n",
       "    (KNeighborsClassifier(n_neighbors=2, weights='distance'),\n",
       "     0.6752380952380952),\n",
       "    (KNeighborsClassifier(n_neighbors=31, weights='distance'),\n",
       "     0.6628571428571428),\n",
       "    (KNeighborsClassifier(n_neighbors=28), 0.6142857142857143),\n",
       "    (KNeighborsClassifier(n_neighbors=2), 0.6857142857142857)]}},\n",
       " 'LungSound': {'SVM': {'init': SVC(C=10, gamma=1),\n",
       "   'ensemble': [(SVC(C=1, gamma=1), 0.7751310425160163),\n",
       "    (SVC(C=10, gamma=1), 0.7751310425160163),\n",
       "    (SVC(C=10, gamma=1), 0.7548825470782372),\n",
       "    (SVC(C=10, gamma=1), 0.7470199961172588),\n",
       "    (SVC(C=0.1, gamma=1), 0.782605319355465)]},\n",
       "  'LR': {'init': LogisticRegression(C=10.0),\n",
       "   'ensemble': [(LogisticRegression(C=0.001), 0.6745486313337217),\n",
       "    (LogisticRegression(C=0.001), 0.6765288293535237),\n",
       "    (LogisticRegression(C=0.001), 0.69961172587847),\n",
       "    (LogisticRegression(C=0.001), 0.6304406911279364),\n",
       "    (LogisticRegression(C=0.001), 0.6561250242671327)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=12, n_estimators=300, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=8, n_estimators=200, random_state=0),\n",
       "     0.741642399534071),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.7574451562803338),\n",
       "    (RandomForestClassifier(max_depth=8, n_estimators=200, random_state=0),\n",
       "     0.772743156668608),\n",
       "    (RandomForestClassifier(max_depth=10, n_estimators=300, random_state=0),\n",
       "     0.7114540865851289),\n",
       "    (RandomForestClassifier(max_depth=10, n_estimators=300, random_state=0),\n",
       "     0.7312366530770722)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=4, weights='distance'),\n",
       "   'ensemble': [(KNeighborsClassifier(n_neighbors=24), 0.7475441661813239),\n",
       "    (KNeighborsClassifier(n_neighbors=30), 0.7574063288681808),\n",
       "    (KNeighborsClassifier(n_neighbors=12), 0.7766841390021355),\n",
       "    (KNeighborsClassifier(n_neighbors=20), 0.7470394098233353),\n",
       "    (KNeighborsClassifier(n_neighbors=16), 0.7549407881964667)]}},\n",
       " 'ChlorineConcentration': {'SVM': {'init': SVC(C=1000, gamma=1),\n",
       "   'ensemble': [(SVC(C=0.1, gamma=1), 0.9375965302020524),\n",
       "    (SVC(C=10, gamma=1), 0.947752036390564),\n",
       "    (SVC(C=0.1, gamma=1), 0.9230826192743045),\n",
       "    (SVC(C=0.1, gamma=1), 0.9434042103036073),\n",
       "    (SVC(C=0.1, gamma=1), 0.9317888501004973)]},\n",
       "  'LR': {'init': LogisticRegression(C=100.0),\n",
       "   'ensemble': [(LogisticRegression(C=10.0), 0.5964984660954196),\n",
       "    (LogisticRegression(C=100.0), 0.6153919390669629),\n",
       "    (LogisticRegression(C=10.0), 0.6342113614725484),\n",
       "    (LogisticRegression(C=10.0), 0.6168517930815614),\n",
       "    (LogisticRegression(C=10.0), 0.5862794879932297)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=12, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=12, n_estimators=300, random_state=0),\n",
       "     0.7198878662858352),\n",
       "    (RandomForestClassifier(max_depth=12, random_state=0), 0.7357981593145034),\n",
       "    (RandomForestClassifier(max_depth=10, n_estimators=300, random_state=0),\n",
       "     0.7140696075320004),\n",
       "    (RandomForestClassifier(max_depth=12, n_estimators=200, random_state=0),\n",
       "     0.7474135195176135),\n",
       "    (RandomForestClassifier(max_depth=10, random_state=0),\n",
       "     0.7489051094890511)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=1),\n",
       "   'ensemble': [(KNeighborsClassifier(n_neighbors=2), 0.9782291336083784),\n",
       "    (KNeighborsClassifier(n_neighbors=2), 0.972432032159103),\n",
       "    (KNeighborsClassifier(n_neighbors=4), 0.9767798582460594),\n",
       "    (KNeighborsClassifier(n_neighbors=6), 0.972432032159103),\n",
       "    (KNeighborsClassifier(), 0.9680736274198669)]}},\n",
       " 'PhalangesOutlinesCorrect': {'SVM': {'init': SVC(C=10, gamma=1),\n",
       "   'ensemble': [(SVC(C=0.1, gamma=1), 0.8122024623803009),\n",
       "    (SVC(C=0.1, gamma=1), 0.8188235294117646),\n",
       "    (SVC(C=0.1, gamma=1), 0.8023529411764706),\n",
       "    (SVC(C=0.1, gamma=1), 0.8),\n",
       "    (SVC(C=0.1, gamma=1), 0.8117647058823529)]},\n",
       "  'LR': {'init': LogisticRegression(C=1000.0),\n",
       "   'ensemble': [(LogisticRegression(C=0.001), 0.7957865937072504),\n",
       "    (LogisticRegression(C=0.001), 0.8305882352941175),\n",
       "    (LogisticRegression(C=0.001), 0.7764705882352941),\n",
       "    (LogisticRegression(C=0.001), 0.8047058823529412),\n",
       "    (LogisticRegression(C=0.001), 0.7811764705882352)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=12, n_estimators=300, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=8, n_estimators=200, random_state=0),\n",
       "     0.8380300957592339),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.823529411764706),\n",
       "    (RandomForestClassifier(max_depth=12, n_estimators=200, random_state=0),\n",
       "     0.7858823529411765),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.8070588235294117),\n",
       "    (RandomForestClassifier(max_depth=8, n_estimators=300, random_state=0),\n",
       "     0.7952941176470588)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=8),\n",
       "   'ensemble': [(KNeighborsClassifier(n_neighbors=2), 0.828563611491108),\n",
       "    (KNeighborsClassifier(n_neighbors=14), 0.7788235294117647),\n",
       "    (KNeighborsClassifier(n_neighbors=24), 0.7788235294117647),\n",
       "    (KNeighborsClassifier(n_neighbors=12), 0.7717647058823529),\n",
       "    (KNeighborsClassifier(n_neighbors=2), 0.7858823529411765)]}},\n",
       " 'DistalPhalanxOutlineCorrect': {'SVM': {'init': SVC(C=10, gamma=1),\n",
       "   'ensemble': [(SVC(C=10, gamma=0.1), 0.8357142857142857),\n",
       "    (SVC(C=0.1, gamma=1), 0.8428571428571427),\n",
       "    (SVC(C=0.1, gamma=1), 0.8142857142857143),\n",
       "    (SVC(C=0.1, gamma=1), 0.8071428571428572),\n",
       "    (SVC(C=0.1, gamma=1), 0.85)]},\n",
       "  'LR': {'init': LogisticRegression(),\n",
       "   'ensemble': [(LogisticRegression(C=0.001), 0.8214285714285714),\n",
       "    (LogisticRegression(C=0.001), 0.8285714285714285),\n",
       "    (LogisticRegression(C=0.001), 0.8214285714285714),\n",
       "    (LogisticRegression(C=0.001), 0.7642857142857142),\n",
       "    (LogisticRegression(C=0.001), 0.8428571428571427)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=8, n_estimators=300, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=8, n_estimators=200, random_state=0),\n",
       "     0.8285714285714286),\n",
       "    (RandomForestClassifier(max_depth=10, n_estimators=200, random_state=0),\n",
       "     0.8142857142857143),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.8),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.7785714285714286),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0),\n",
       "     0.8142857142857143)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=10),\n",
       "   'ensemble': [(KNeighborsClassifier(n_neighbors=6), 0.8285714285714286),\n",
       "    (KNeighborsClassifier(n_neighbors=2), 0.85),\n",
       "    (KNeighborsClassifier(n_neighbors=10), 0.7642857142857142),\n",
       "    (KNeighborsClassifier(n_neighbors=4, weights='distance'),\n",
       "     0.7928571428571429),\n",
       "    (KNeighborsClassifier(n_neighbors=12), 0.8285714285714285)]}},\n",
       " 'CricketZ': {'SVM': {'init': SVC(C=10, gamma=1),\n",
       "   'ensemble': [(SVC(C=1000, gamma=0.001), 0.64),\n",
       "    (SVC(C=1000, gamma=1), 0.656),\n",
       "    (SVC(C=1, gamma=1), 0.68),\n",
       "    (SVC(C=1000, gamma=0.01), 0.736),\n",
       "    (SVC(C=100, gamma=0.1), 0.6303333333333334)]},\n",
       "  'LR': {'init': LogisticRegression(C=100.0),\n",
       "   'ensemble': [(LogisticRegression(), 0.68),\n",
       "    (LogisticRegression(C=0.1), 0.624),\n",
       "    (LogisticRegression(), 0.64),\n",
       "    (LogisticRegression(C=10.0), 0.736),\n",
       "    (LogisticRegression(C=10.0), 0.6226666666666667)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=10, n_estimators=200, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=10, n_estimators=300, random_state=0),\n",
       "     0.672),\n",
       "    (RandomForestClassifier(max_depth=10, n_estimators=300, random_state=0),\n",
       "     0.6719999999999999),\n",
       "    (RandomForestClassifier(max_depth=8, n_estimators=300, random_state=0),\n",
       "     0.696),\n",
       "    (RandomForestClassifier(max_depth=8, n_estimators=200, random_state=0),\n",
       "     0.712),\n",
       "    (RandomForestClassifier(max_depth=8, n_estimators=200, random_state=0),\n",
       "     0.6380000000000001)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=6, weights='distance'),\n",
       "   'ensemble': [(KNeighborsClassifier(n_neighbors=20, weights='distance'),\n",
       "     0.64),\n",
       "    (KNeighborsClassifier(), 0.744),\n",
       "    (KNeighborsClassifier(n_neighbors=6, weights='distance'),\n",
       "     0.6880000000000001),\n",
       "    (KNeighborsClassifier(n_neighbors=20, weights='distance'), 0.696),\n",
       "    (KNeighborsClassifier(n_neighbors=16, weights='distance'),\n",
       "     0.6216666666666667)]}},\n",
       " 'ECG200': {'SVM': {'init': SVC(C=10, gamma=0.1),\n",
       "   'ensemble': [(SVC(C=0.1, gamma=1), 0.9428571428571428),\n",
       "    (SVC(C=0.1, gamma=1), 0.9428571428571428),\n",
       "    (SVC(C=0.1, gamma=1), 0.8761904761904763),\n",
       "    (SVC(C=0.1, gamma=1), 0.9428571428571428),\n",
       "    (SVC(C=0.1, gamma=1), 0.9095238095238095)]},\n",
       "  'LR': {'init': LogisticRegression(C=10.0),\n",
       "   'ensemble': [(LogisticRegression(C=0.001), 0.9095238095238095),\n",
       "    (LogisticRegression(C=0.001), 0.9428571428571428),\n",
       "    (LogisticRegression(C=0.001), 0.7857142857142858),\n",
       "    (LogisticRegression(C=100.0), 0.9380952380952381),\n",
       "    (LogisticRegression(C=0.001), 0.8761904761904763)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=10, n_estimators=200, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=8, random_state=0),\n",
       "     0.9428571428571428),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.9428571428571428),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.8142857142857143),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.9095238095238095),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0),\n",
       "     0.9095238095238095)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=4, weights='distance'),\n",
       "   'ensemble': [(KNeighborsClassifier(n_neighbors=6), 0.9095238095238095),\n",
       "    (KNeighborsClassifier(n_neighbors=1), 0.9095238095238095),\n",
       "    (KNeighborsClassifier(n_neighbors=4), 0.8761904761904763),\n",
       "    (KNeighborsClassifier(n_neighbors=1), 0.9428571428571428),\n",
       "    (KNeighborsClassifier(n_neighbors=2), 0.9095238095238095)]}},\n",
       " 'ERing': {'SVM': {'init': SVC(C=100, gamma=0.1),\n",
       "   'ensemble': [(SVC(C=0.1, gamma=1), 0.9400000000000001),\n",
       "    (SVC(C=0.1, gamma=1), 0.8955555555555555),\n",
       "    (SVC(C=0.1, gamma=1), 0.9177777777777777),\n",
       "    (SVC(C=0.1, gamma=1), 0.9177777777777777),\n",
       "    (SVC(C=0.1, gamma=1), 0.9177777777777777)]},\n",
       "  'LR': {'init': LogisticRegression(),\n",
       "   'ensemble': [(LogisticRegression(C=0.001), 0.9400000000000001),\n",
       "    (LogisticRegression(C=0.001), 0.9177777777777777),\n",
       "    (LogisticRegression(C=10.0), 0.9355555555555555),\n",
       "    (LogisticRegression(C=0.001), 0.8755555555555556),\n",
       "    (LogisticRegression(C=1000.0), 0.86)]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=8, random_state=0),\n",
       "   'ensemble': [(RandomForestClassifier(max_depth=8, random_state=0),\n",
       "     0.9177777777777777),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.9177777777777777),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.9177777777777777),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0), 0.8955555555555555),\n",
       "    (RandomForestClassifier(max_depth=8, random_state=0),\n",
       "     0.9177777777777777)]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=2),\n",
       "   'ensemble': [(KNeighborsClassifier(n_neighbors=2), 0.9177777777777777),\n",
       "    (KNeighborsClassifier(n_neighbors=2), 0.8755555555555556),\n",
       "    (KNeighborsClassifier(n_neighbors=3), 0.9155555555555555),\n",
       "    (KNeighborsClassifier(n_neighbors=10), 0.8355555555555556),\n",
       "    (KNeighborsClassifier(n_neighbors=6), 0.7911111111111111)]}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mathematical-midwest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ArrowHead': {'SVM': {'init': SVC(C=100, gamma=0.1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'LR': {'init': LogisticRegression(C=100.0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=8, random_state=0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]}},\n",
       " 'OSULeaf': {'SVM': {'init': SVC(C=1000, gamma=0.1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'LR': {'init': LogisticRegression(C=100.0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=12, random_state=0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=4, weights='distance'),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]}},\n",
       " 'ECG200': {'SVM': {'init': SVC(C=10, gamma=0.1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'LR': {'init': LogisticRegression(C=10.0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=10, n_estimators=200, random_state=0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=4, weights='distance'),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]}},\n",
       " 'ChlorineConcentration': {'SVM': {'init': SVC(C=1000, gamma=1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'LR': {'init': LogisticRegression(C=100.0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=12, random_state=0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]}},\n",
       " 'PhalangesOutlinesCorrect': {'SVM': {'init': SVC(C=10, gamma=1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'LR': {'init': LogisticRegression(C=1000.0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=12, n_estimators=300, random_state=0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=8),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]}},\n",
       " 'DistalPhalanxOutlineCorrect': {'SVM': {'init': SVC(C=10, gamma=1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'LR': {'init': LogisticRegression(),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=8, n_estimators=300, random_state=0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=10),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]}},\n",
       " 'CricketZ': {'SVM': {'init': SVC(C=10, gamma=1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'LR': {'init': LogisticRegression(C=100.0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=10, n_estimators=200, random_state=0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=6, weights='distance'),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]}},\n",
       " 'ERing': {'SVM': {'init': SVC(C=100, gamma=0.1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'LR': {'init': LogisticRegression(),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=8, random_state=0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=2),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]}},\n",
       " 'Colposcopy': {'SVM': {'init': SVC(C=1, gamma=1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'LR': {'init': LogisticRegression(C=0.1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=12, random_state=0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=17, weights='distance'),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]}},\n",
       " 'Epilepsy': {'SVM': {'init': SVC(C=10, gamma=0.1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'LR': {'init': LogisticRegression(C=100.0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=8, random_state=0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]}},\n",
       " 'EyesOpenShut': {'SVM': {'init': SVC(C=1, gamma=1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'LR': {'init': LogisticRegression(C=0.1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=10, random_state=0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'KNN': {'init': KNeighborsClassifier(weights='distance'),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]}},\n",
       " 'FingerMovements': {'SVM': {'init': SVC(C=10, gamma=1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'LR': {'init': LogisticRegression(C=0.1),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'RF': {'init': RandomForestClassifier(max_depth=8, random_state=0),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]},\n",
       "  'KNN': {'init': KNeighborsClassifier(n_neighbors=15),\n",
       "   'ensemble': [LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear'),\n",
       "    LogisticRegression(class_weight='balanced', penalty='l1', random_state=0,\n",
       "                       solver='liblinear')]}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "parallel-receptor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a_file = open(module_path + '/src/dictionaries/classifier_dict_lr_helper.pkl', 'wb')\n",
    "pickle.dump(dict_classifiers, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "moving-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(module_path + '/src/dictionaries/classifier_dict.pkl', 'wb')\n",
    "pickle.dump(joined, a_file)\n",
    "a_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
