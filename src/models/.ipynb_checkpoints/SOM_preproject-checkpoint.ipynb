{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Organized Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "sys.path.insert(1, module_path + '/src/')\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning, DataConversionWarning, FitFailedWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FitFailedWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "\n",
    "\n",
    "import utility\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "font = FontProperties(fname = module_path + '/src/visualization/CharterRegular.ttf', size = 10, weight = 1000)\n",
    "font_small = FontProperties(fname = module_path + '/src/visualization/CharterRegular.ttf', size = 8, weight = 1000)\n",
    "\n",
    "\n",
    "from sktime.datasets import load_UCR_UEA_dataset\n",
    "from sktime.transformations.panel.catch22_features import Catch22\n",
    "\n",
    "\n",
    "def get_dataset_partitions(X, y, ft = 'rocket', fs = 'pca'):\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    norm = MinMaxScaler()\n",
    "    X_train_full = pd.DataFrame(norm.fit_transform(X_train_full))\n",
    "    X_test = pd.DataFrame(norm.fit_transform(X_test))\n",
    "    k = min([X_test.shape[0], 100])\n",
    "    print('Chosen number of components: ', k)\n",
    "    if (ft == 'rocket') and (fs == 'pca'):  \n",
    "        pca = PCA(n_components = k)\n",
    "        X_train_full = pca.fit_transform(X_train_full)\n",
    "        X_train_full = pd.DataFrame(X_train_full)\n",
    "        \n",
    "        X_test = pca.fit_transform(X_test)\n",
    "        X_test = pd.DataFrame(X_test)\n",
    "    elif (ft == 'rocket') and (fs == 'select'):\n",
    "        select = SelectKBest(chi2, k=k)\n",
    "        X_train_full = select.fit_transform(X_train_full, y_train_full)\n",
    "        indices = select.get_support(indices = True)\n",
    "        X_test = X_test[indices]\n",
    "    return pd.DataFrame(X_train_full), y_train_full, pd.DataFrame(X_test), y_test\n",
    "\n",
    "\n",
    "def get_initial_classifier(X_train_full,y_train_full, clf, grid, no_grid_search = False):\n",
    "    grid_cv=GridSearchCV(clf,grid,cv=5)\n",
    "    grid_cv.fit(X_train_full,y_train_full)\n",
    "    return grid_cv.best_estimator_\n",
    "\n",
    "def get_helping_classifier(X_train, y_train, X_val, y_val, clf, grid):\n",
    "    '''Get the helping classifier\n",
    "    \n",
    "    returns a classifier, which classifies if something is likely to be classified wrongly\n",
    "    \n",
    "    '''\n",
    "    new_X = X_val\n",
    "\n",
    "    grid_cv=GridSearchCV(clf,grid,cv=5)\n",
    "    grid_cv.fit(X_train,y_train)\n",
    "    clf_2 = grid_cv.best_estimator_\n",
    "        \n",
    "    y_pred = clf_2.predict(X_val)\n",
    "    new_y = pd.Series(np.hstack([y_pred != y_val]))\n",
    "    \n",
    "    grid_cv=GridSearchCV(clf,grid,cv=5)\n",
    "    grid_cv.fit(new_X,new_y)\n",
    "    return grid_cv.best_estimator_ , grid_cv.best_score_\n",
    "\n",
    "\n",
    "\n",
    "def get_helping_classifier_alt(X_train, y_train, X_val, y_val, clf, grid):\n",
    "    '''Get the helping classifier\n",
    "    \n",
    "    returns a classifier, which classifies if something is likely to be classified wrongly\n",
    "    \n",
    "    ALT: Here a Logisic regression classifier is always used \n",
    "    to detect if a sample is likely to be classified incorrectly\n",
    "    '''\n",
    "    grid_cv=GridSearchCV(clf,grid,cv=5)\n",
    "    grid_cv.fit(X_train,y_train)\n",
    "    clf = grid_cv.best_estimator_\n",
    "    \n",
    "    y_pred = clf.predict(X_val)\n",
    "    new_X = X_val\n",
    "    new_y = pd.Series(np.hstack([y_pred != y_val]))\n",
    "    \n",
    "    grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\n",
    "    clf=LogisticRegression()\n",
    "    grid_cv=GridSearchCV(clf,grid,cv=5)\n",
    "    grid_cv.fit(new_X,new_y)\n",
    "    \n",
    "    return grid_cv.best_estimator_ , grid_cv.best_score_\n",
    "\n",
    "def get_ensemble_helping_classifier(X_train, y_train, clf, grid):\n",
    "    kf = KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "    #kf.get_n_splits(X_train)\n",
    "    classifiers = []\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        clf_temp, score_temp = get_helping_classifier(X_train.iloc[train_index], y_train.iloc[train_index], X_train.iloc[val_index], y_train.iloc[val_index], clf, grid)\n",
    "        classifiers.append((clf_temp, score_temp))\n",
    "    return classifiers\n",
    "\n",
    "def make_ensemble_classification(X_test, ensemble):\n",
    "    y_pred = []\n",
    "    for e in ensemble: \n",
    "        clf = e[0]\n",
    "        score = e[1]\n",
    "        y_pred_temp = clf.predict(X_test)\n",
    "        y_pred.append((score * (y_pred_temp + 1)) -1)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_sum = y_pred.sum(axis = 0)\n",
    "    idx_true = np.where(y_pred_sum > 0)[0]\n",
    "    \n",
    "    y_pred = y_pred.mean(axis = 0)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    \n",
    "    y_pred[idx_true] = 1\n",
    "    return y_pred\n",
    "\n",
    "def filter_test_set_ensemble(X_test, y_test, ensemble):\n",
    "    y_pred = make_ensemble_classification(X_test, ensemble)\n",
    "    to_del = np.where(y_pred == 1)[0]\n",
    "    X_test = X_test.reset_index(drop = True)\n",
    "    y_test = y_test.reset_index(drop = True)\n",
    "    X_test_new = X_test[~X_test.index.isin(to_del)]\n",
    "    y_test_new = y_test[~y_test.index.isin(to_del)]\n",
    "    return X_test_new, y_test_new\n",
    "\n",
    "\n",
    "def plot_cm(clf, X_test, y_test, class_names, color_index = 2):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    colors = [\"#F94144\", \"#F3722C\", '#F8961E', '#F9C74F','#90BE6D', '#43AA8B','#577590']\n",
    "\n",
    "    font = FontProperties(fname = module_path + '/src/visualization/CharterRegular.ttf', size = 10, weight = 1000)\n",
    "\n",
    "    colors_2 = ['#FFFFFF', colors[color_index]]\n",
    "    cmap_name = 'my colormap'\n",
    "    font_small = FontProperties(fname =  module_path + '/src/visualization/CharterRegular.ttf', size = 6, weight = 1000)\n",
    "\n",
    "    cm_map = LinearSegmentedColormap.from_list(cmap_name, colors_2)\n",
    "\n",
    "\n",
    "    f, ax = plt.subplots(1,1) # 1 x 1 array , can also be any other size\n",
    "    f.set_size_inches(5, 5)\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    ax = sns.heatmap(cm, annot=True,\n",
    "                fmt='.2%', cmap=cm_map, xticklabels=class_names,yticklabels=class_names )\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    for label in ax.get_yticklabels() :\n",
    "        label.set_fontproperties(font_small)\n",
    "    for label in ax.get_xticklabels() :\n",
    "        label.set_fontproperties(font_small)\n",
    "    ax.set_ylabel('True Label', fontproperties = font)\n",
    "    ax.set_xlabel('Predicted Label', fontproperties = font)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 0)\n",
    "\n",
    "    for child in ax.get_children():\n",
    "        if isinstance(child, matplotlib.text.Text):\n",
    "            child.set_fontproperties(font)\n",
    "    for l in cbar.ax.yaxis.get_ticklabels():\n",
    "        l.set_fontproperties(font_small)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_and_plot_to_compare(X_test, y_test, X_test_2, y_test_2, clf, class_names):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc_1 = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy score for the initial classification: {acc_1} ')\n",
    "    plot_cm(clf, X_test, y_test, class_names)\n",
    "    \n",
    "    y_pred_2 = clf.predict(X_test_2)\n",
    "    acc_2 = accuracy_score(y_test_2, y_pred_2)\n",
    "    print(f'Accuracy score for the double classification: {acc_2} ')\n",
    "    plot_cm(clf, X_test_2, y_test_2, class_names, color_index = 5)\n",
    "    return acc_1 , acc_2\n",
    "    \n",
    "def compare_single_double_classifier(name_UCR, class_names, result_dict, feature_transform = 'rocket', feature_select = 'pca'):    \n",
    "    if name_UCR != 'lungSound':\n",
    "        X, y = load_UCR_UEA_dataset(name_UCR, return_X_y=True)\n",
    "    else: \n",
    "        X, y = load_from_tsfile_to_dataframe(module_path + '/data/ts_files/crackleNoCrackleSamleLength3000.ts')\n",
    "    if (feature_transform == 'rocket'):\n",
    "        rocket = Rocket()  # by default, ROCKET uses 10,000 kernels\n",
    "        rocket.fit(X)\n",
    "        X = rocket.transform(X)\n",
    "    else:\n",
    "        c22f = Catch22()\n",
    "        c22f.fit(X, y)\n",
    "        X = c22f.transform(X)\n",
    "    X_train_full, y_train_full , X_test, y_test = get_dataset_partitions(X,y, feature_transform, feature_select)\n",
    "    ############ K nearest neighbours \n",
    "    max_nn = round((0.8*X.shape[0])//8)\n",
    "    k_range = list(range(1,max_nn))\n",
    "    weight_options = [\"uniform\", \"distance\"]\n",
    "    grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "    clf = KNeighborsClassifier()\n",
    "\n",
    "    clf_full = get_initial_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    clf_ensemble = get_ensemble_helping_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    X_test_2, y_test_2 = filter_test_set_ensemble(X_test, y_test, clf_ensemble)\n",
    "\n",
    "    print('K-NN results:')\n",
    "    acc_1, acc_2 = print_and_plot_to_compare(X_test, y_test, X_test_2, y_test_2, clf_full, class_names)\n",
    "    result_dict[ f'K-nn, {feature_transform}, {feature_select}'] = acc_1\n",
    "    result_dict[ f'K-nn double, {feature_transform}, {feature_select}'] = acc_2\n",
    "\n",
    "\n",
    "    grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\"]}\n",
    "    clf=LogisticRegression()\n",
    "\n",
    "    clf_full = get_initial_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    clf_ensemble = get_ensemble_helping_classifier(X_train_full, y_train_full, clf, grid)\n",
    "    X_test_2, y_test_2 = filter_test_set_ensemble(X_test, y_test, clf_ensemble)\n",
    "\n",
    "    print('Logistic Regression results: ')\n",
    "    acc_1, acc_2 = print_and_plot_to_compare(X_test, y_test, X_test_2, y_test_2, clf_full, class_names)\n",
    "    result_dict[ f'Logistic reg, {feature_transform}, {feature_select}'] = acc_1\n",
    "    result_dict[ f'Logistic reg double, {feature_transform}, {feature_select}'] = acc_2\n",
    "    return result_dict\n",
    "\n",
    "def compare_rocket_c22(name_UCR, class_names):\n",
    "    print('%%%%%%%%%%%%%%%% \\n\\n FEATURE SELECTION = PCA ')\n",
    "    print('%%%%%%%%%%%%%%%% \\n\\n ROCKET ')\n",
    "    start = time.time()\n",
    "    ret_dict = {}\n",
    "    ret_dict = compare_single_double_classifier(name_UCR, class_names, ret_dict, feature_transform='rocket', feature_select = 'pca')\n",
    "    \n",
    "    print('Time to compute ROCKET: ', (time.time() - start))\n",
    "\n",
    "    print('%%%%%%%%%%%%%%%% \\n\\n C22 ')\n",
    "    start = time.time()\n",
    "    ret_dict = compare_single_double_classifier(name_UCR, class_names,ret_dict, feature_transform='c22')\n",
    "    print('Time to compute c22: ', (time.time() - start))\n",
    "    \n",
    "    print('%%%%%%%%%%%%%%%% \\n\\n FEATURE SELECTION = SELECT K BEST ')\n",
    "    print('%%%%%%%%%%%%%%%% \\n\\n ROCKET ')\n",
    "    start = time.time()\n",
    "    ret_dict = compare_single_double_classifier(name_UCR, class_names,ret_dict, feature_transform='rocket', feature_select = 'select')\n",
    "    print('Time to compute ROCKET: ', (time.time() - start))\n",
    "\n",
    "    print('%%%%%%%%%%%%%%%% \\n\\n c22 ')\n",
    "    start = time.time()\n",
    "    ret_dict = compare_single_double_classifier(name_UCR, class_names, ret_dict, feature_transform='c22')\n",
    "    print('Time to compute c22: ', (time.time() - start))\n",
    "    return ret_dict\n",
    "\n",
    "def classify(som, data, X_train, y_train):\n",
    "    \"\"\"Classifies each sample in data in one of the classes definited\n",
    "    using the method labels_map.\n",
    "    Returns a list of the same length of data where the i-th element\n",
    "    is the class assigned to data[i].\n",
    "    \"\"\"\n",
    "    winmap = som.labels_map(X_train, y_train)\n",
    "    default_class = np.sum(list(winmap.values())).most_common()[0][0]\n",
    "    result = []\n",
    "    for d in data:\n",
    "        win_position = som.winner(d)\n",
    "        if win_position in winmap:\n",
    "            result.append(winmap[win_position].most_common()[0][0])\n",
    "        else:\n",
    "            result.append(default_class)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from minisom import MiniSom\n",
    "from sklearn.preprocessing import minmax_scale, scale\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib\n",
    "from sklearn.metrics import classification_report\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "sys.path.insert(1, module_path + '/src')\n",
    "\n",
    "import utility\n",
    "    \n",
    "def classify(som, data, X_train, y_train):\n",
    "    \"\"\"Classifies each sample in data in one of the classes definited\n",
    "    using the method labels_map.\n",
    "    Returns a list of the same length of data where the i-th element\n",
    "    is the class assigned to data[i].\n",
    "    \"\"\"\n",
    "    winmap = som.labels_map(X_train, y_train)\n",
    "    default_class = np.sum(list(winmap.values())).most_common()[0][0]\n",
    "    result = []\n",
    "    for d in data:\n",
    "        win_position = som.winner(d)\n",
    "        if win_position in winmap:\n",
    "            result.append(winmap[win_position].most_common()[0][0])\n",
    "        else:\n",
    "            result.append(default_class)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 30)\n",
      "(594,)\n",
      "1780\n",
      "Decomposition method: noDecomp \n",
      " \n",
      " \n",
      "(594, 30)\n",
      "(594,)\n",
      "1780\n",
      "Decomposition method: EMD \n",
      " \n",
      " \n",
      "(594, 30)\n",
      "(594,)\n",
      "1780\n",
      "Decomposition method: EEMD \n",
      " \n",
      " \n",
      "(594, 30)\n",
      "(594,)\n",
      "1780\n",
      "Decomposition method: DWT \n",
      " \n",
      " \n",
      "(594, 30)\n",
      "(594,)\n",
      "1780\n",
      "Decomposition method: EMD_DWT \n",
      " \n",
      " \n",
      "(594, 30)\n",
      "(594,)\n",
      "1780\n",
      "Decomposition method: EEMD_DWT \n",
      " \n",
      " \n",
      "{'SOM & noDecomp': {'accuracy': 0.6654040404040404, 'precision': 0.6668217253216131, 'recall': 0.6658163265306123, 'f1-score': 0.6650147238382531}, 'SOM & EMD': {'accuracy': 0.6363636363636364, 'precision': 0.63922081961689, 'recall': 0.637015306122449, 'f1-score': 0.6351328005528292}, 'SOM & EEMD': {'accuracy': 0.6590909090909091, 'precision': 0.6618616677440207, 'recall': 0.6596938775510204, 'f1-score': 0.6581294964028777}, 'SOM & DWT': {'accuracy': 0.6691919191919192, 'precision': 0.6748917748917749, 'recall': 0.6700510204081632, 'f1-score': 0.667152160662154}, 'SOM & EMD_DWT': {'accuracy': 0.6224747474747475, 'precision': 0.6267178273948004, 'recall': 0.6233163265306123, 'f1-score': 0.6202218612028361}, 'SOM & EEMD_DWT': {'accuracy': 0.6502525252525253, 'precision': 0.6524091919940697, 'recall': 0.6507908163265306, 'f1-score': 0.6494875338515246}}\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n"
     ]
    }
   ],
   "source": [
    "size_som = 13\n",
    "decomp_methods = ['noDecomp', 'EMD', 'EEMD', 'DWT',  'EMD_DWT','EEMD_DWT']\n",
    "metrics = {}\n",
    "for decomp in decomp_methods:\n",
    "    \n",
    "    X,y = utility.get_X_y('noDecomp', fs_pca = True, k = 30)\n",
    "\n",
    "    try:\n",
    "        data , labels = X.to_numpy(),y.to_numpy() \n",
    "    except AttributeError:\n",
    "        data , labels = X,y.to_numpy() \n",
    "           \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, stratify=labels)\n",
    "    X_train, X_val, y_train, y_val =  train_test_split(X_train, y_train, stratify=y_train)\n",
    "    \n",
    "    print(X_val.shape)\n",
    "    print(y_val.shape)\n",
    "    som = MiniSom(size_som, size_som, data.shape[1], sigma=5, learning_rate=0.5, \n",
    "                  neighborhood_function='triangle', random_seed=10)\n",
    "    som.pca_weights_init(X_train)\n",
    "    som.train_random(X_train, 2500)\n",
    "\n",
    "    y_pred = classify(som, X_test, X_train, y_train)\n",
    "    print(len(y_train))\n",
    "    rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    metrics['SOM & '+ decomp] = {'accuracy': rep['accuracy'], \n",
    "                       'precision': rep['macro avg']['precision'],\n",
    "                       'recall': rep['macro avg']['recall'],\n",
    "                       'f1-score': rep['macro avg']['f1-score']}\n",
    "\n",
    "    print(f'Decomposition method: {decomp} \\n \\n ')\n",
    "    #utility.report_to_latex_table(rep)\n",
    "    #utility.plot_conf_matrix(y_test, y_pred, decomp, 'SOM')\n",
    "print(metrics)\n",
    "print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = 'noDecomp'\n",
    "X_Y = {\n",
    "   'Filtering': utility.get_X_y(decomp, fs_filter= True,k = 30),\n",
    "    'PCA': utility.get_X_y(decomp, fs_pca= True,k = 30),\n",
    "\n",
    "    'Autoencoder': utility.get_X_y(decomp, fs_auto_encoder= True,k = 30), \n",
    "    'No feature selection': utility.get_X_y(decomp), \n",
    "    \n",
    "}\n",
    "metrics = {}\n",
    "for key, val in X_Y.items():\n",
    "    X, y = val\n",
    "    \n",
    "    try:\n",
    "        data , labels = X.to_numpy(),y.to_numpy() \n",
    "    except AttributeError:\n",
    "        data , labels = X,y.to_numpy() \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, stratify=labels)\n",
    "    X_train, X_val, y_train, y_val =  train_test_split(X_train, y_train, stratify=y_train)\n",
    "    \n",
    "    som = MiniSom(size_som, size_som, data.shape[1], sigma=5, learning_rate=0.5, \n",
    "                  neighborhood_function='triangle', random_seed=10)\n",
    "    som.pca_weights_init(X_train)\n",
    "    som.train_random(X_train, 2500)\n",
    "\n",
    "    y_pred = classify(som, X_test, X_train, y_train)\n",
    "\n",
    "    rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    metrics['SOM, ' + key] = {'accuracy': rep['accuracy'], \n",
    "                       'precision': rep['macro avg']['precision'],\n",
    "                       'recall': rep['macro avg']['recall'],\n",
    "                       'f1-score': rep['macro avg']['f1-score']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SOM, Filtering': {'accuracy': 0.6477272727272727,\n",
       "  'precision': 0.6496764222930551,\n",
       "  'recall': 0.6482397959183674,\n",
       "  'f1-score': 0.6470379640884993},\n",
       " 'SOM, PCA': {'accuracy': 0.6755050505050505,\n",
       "  'precision': 0.6777262629189607,\n",
       "  'recall': 0.6760204081632653,\n",
       "  'f1-score': 0.6748700959524886},\n",
       " 'SOM, Autoencoder': {'accuracy': 0.6161616161616161,\n",
       "  'precision': 0.6161616161616161,\n",
       "  'recall': 0.6161734693877551,\n",
       "  'f1-score': 0.6161518251154248},\n",
       " 'SOM, No feature selection': {'accuracy': 0.6679292929292929,\n",
       "  'precision': 0.6693625485226653,\n",
       "  'recall': 0.6683418367346938,\n",
       "  'f1-score': 0.6675429146017382}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
