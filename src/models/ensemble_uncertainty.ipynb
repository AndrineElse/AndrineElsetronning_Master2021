{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep ensemble for uncertainty estimation\n",
    "\n",
    "https://medium.com/@albertoarrigoni/paper-review-code-deep-ensembles-nips-2017-c5859070b8ce\n",
    "https://github.com/vvanirudh/deep-ensembles-uncertainty/blob/master/model.py\n",
    "https://github.com/muupan/deep-ensemble-uncertainty/blob/master/train_ensemble.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "sys.path.insert(1, module_path + '/src')\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n",
    "from sktime.utils.data_io import load_from_tsfile_to_dataframe\n",
    "from sktime.utils.data_processing import from_nested_to_2d_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "#X_train, y_train = load_from_tsfile_to_dataframe(module_path + '/features/extracted_features_ts_files/uit_MiniROCKET_TRAIN.ts')\n",
    "#X_test, y_test = load_from_tsfile_to_dataframe(module_path + '/features/extracted_features_ts_files/uit_MiniROCKET_TEST.ts')\n",
    "\n",
    "X_train, y_train_ = load_from_tsfile_to_dataframe(module_path + '/data/ts_files/UiT_5s_noOverlap_TRAIN.ts')\n",
    "X_test, y_test_ = load_from_tsfile_to_dataframe(module_path + '/data/ts_files/UiT_5s_noOverlap_TEST.ts')\n",
    "X_val, y_val_ = load_from_tsfile_to_dataframe(module_path + '/data/ts_files/UiT_5s_noOverlap_VAL.ts')\n",
    "\n",
    "\n",
    "X_train = from_nested_to_2d_array(X_train)\n",
    "X_test = from_nested_to_2d_array(X_test)\n",
    "X_val = from_nested_to_2d_array(X_val)\n",
    "\n",
    "X_train.columns = np.arange(len(X_train.columns))\n",
    "X_test.columns = np.arange(len(X_test.columns))\n",
    "X_val.columns = np.arange(len(X_val.columns))\n",
    "\n",
    "y_train_ = pd.Series(y_train_)\n",
    "y_test_ = pd.Series(y_test_)\n",
    "y_val_ = pd.Series(y_val_)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = min_max_scaler.fit(X_train)\n",
    "X_train = min_max_scaler.transform(X_train)\n",
    "X_test = min_max_scaler.transform(X_test)\n",
    "X_val = min_max_scaler.transform(X_val)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1], 1)\n",
    "X_val = X_val.reshape(X_val.shape[0],X_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(y_train_)\n",
    "num_classes = len(le.classes_)\n",
    "y_train = le.transform(y_train_)\n",
    "y_test = le.transform(y_test_)\n",
    "y_val = le.transform(y_val_)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes = num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes = num_classes)\n",
    "y_val = np_utils.to_categorical(y_val, num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified Layers in NN\n",
    "\n",
    "A proper scoring rule needs to be used. In this case the final layer of the neural network should output the mean and the variance, to take into account the predictive uncertainty. \n",
    "\n",
    "The custom loss function treats the observed value as a sample from a Gaussian distribution. Using the predicted mean and variance the negative log loss is calculated as the custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import math\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Layer, Dropout, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.initializers import glorot_normal\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def custom_loss(sigma):\n",
    "    def gaussian_loss(y_true, y_pred):\n",
    "        fir = 0.5*math.log(sigma)\n",
    "        sec = 0.5*math.divide(math.square(y_true - y_pred), sigma)\n",
    "        res = math.reduce_mean(fir + sec, axis = -1) + 1e-6\n",
    "        return res\n",
    "    return gaussian_loss\n",
    "\n",
    "\n",
    "\n",
    "class GaussianLayer(Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(GaussianLayer, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.kernel_1 = self.add_weight(name='kernel_1', \n",
    "                                      shape=(30, self.output_dim),\n",
    "                                      initializer=glorot_normal(),\n",
    "                                      trainable=True)\n",
    "        self.kernel_2 = self.add_weight(name='kernel_2', \n",
    "                                      shape=(30, self.output_dim),\n",
    "                                      initializer=glorot_normal(),\n",
    "                                      trainable=True)\n",
    "        self.bias_1 = self.add_weight(name='bias_1',\n",
    "                                    shape=(self.output_dim, ),\n",
    "                                    initializer=glorot_normal(),\n",
    "                                    trainable=True)\n",
    "        self.bias_2 = self.add_weight(name='bias_2',\n",
    "                                    shape=(self.output_dim, ),\n",
    "                                    initializer=glorot_normal(),\n",
    "                                    trainable=True)\n",
    "        super(GaussianLayer, self).build(input_shape) \n",
    "    def call(self, x):\n",
    "        print(self.kernel_1.shape)\n",
    "        output_mu  = K.dot(x, self.kernel_1) + self.bias_1\n",
    "        output_sig = K.dot(x, self.kernel_2) + self.bias_2\n",
    "        output_sig_pos = K.log(1 + K.exp(output_sig)) + 1e-06  \n",
    "       \n",
    "        return [output_mu, output_sig_pos]\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \n",
    "        return [(input_shape[0], self.output_dim), (input_shape[0], self.output_dim)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 5)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "input_shape=(X_train.shape[1], 1)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Conv1D(filters=10, kernel_size=3, activation='relu')(inputs)\n",
    "x = MaxPooling1D(pool_size=50)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1500, activation='relu')(x)\n",
    "x = Dense(500, activation='relu')(x)\n",
    "x = Dense(30, activation='relu')(x)\n",
    "mu, sigma = GaussianLayer(num_classes, name='main_output')(x)\n",
    "model = Model(inputs, mu)\n",
    "model.compile(loss=custom_loss(sigma), optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_68 (InputLayer)        [(None, 25000, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 24998, 10)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 499, 10)           0         \n",
      "_________________________________________________________________\n",
      "flatten_51 (Flatten)         (None, 4990)              0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 1500)              7486500   \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 500)               750500    \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "main_output (GaussianLayer)  [(None, 5), (None, 5)]    310       \n",
      "=================================================================\n",
      "Total params: 8,252,380\n",
      "Trainable params: 8,252,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to fix the batch problem in the custom loss function here!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples\n",
      "80/80 [==============================] - 2s 30ms/sample - loss: 0.5818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f839b5b2470>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'main_output' # Where to extract the output from\n",
    "get_intermediate = K.function(inputs=[model.input], outputs=model.get_layer(layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25000, 1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([X_train[:80][1]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, sigmas = [], []\n",
    "for j in range(len(X_test[:80])):\n",
    "    mu, sigma = get_intermediate(np.array([X_test[:80][j]]))\n",
    "    preds.append(mu[0])\n",
    "    sigmas.append(sigma[0])\n",
    "    \n",
    "preds = np.array(preds)\n",
    "sigmas = np.array(sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(preds[10].mean(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 5)\n",
      "Train on 2322 samples\n",
      "2322/2322 [==============================] - 11s 5ms/sample - loss: 17.9407\n",
      "(30, 5)\n",
      "Train on 2322 samples\n",
      "2322/2322 [==============================] - 11s 5ms/sample - loss: 0.0361\n",
      "(30, 5)\n",
      "Train on 2322 samples\n",
      "2322/2322 [==============================] - 11s 5ms/sample - loss: 0.2262\n",
      "(30, 5)\n",
      "Train on 2322 samples\n",
      "2322/2322 [==============================] - 11s 5ms/sample - loss: -0.3331\n",
      "(30, 5)\n",
      "Train on 2322 samples\n",
      "2322/2322 [==============================] - 11s 5ms/sample - loss: -0.3246\n",
      "(30, 5)\n",
      "Train on 2322 samples\n",
      "2322/2322 [==============================] - 11s 5ms/sample - loss: 0.0266\n",
      "(30, 5)\n",
      "Train on 2322 samples\n",
      "2322/2322 [==============================] - 11s 5ms/sample - loss: 0.3259\n",
      "(30, 5)\n",
      "Train on 2322 samples\n",
      "2322/2322 [==============================] - 11s 5ms/sample - loss: -0.1689\n",
      "(30, 5)\n",
      "Train on 2322 samples\n",
      "2322/2322 [==============================] - 11s 5ms/sample - loss: 0.2632\n",
      "(30, 5)\n",
      "Train on 2322 samples\n",
      "2322/2322 [==============================] - 11s 5ms/sample - loss: -0.0682\n"
     ]
    }
   ],
   "source": [
    "def create_trained_network(X_train, y_train):\n",
    "    input_shape=(X_train.shape[1], 1)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(filters=10, kernel_size=3, activation='relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size=50)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1500, activation='relu')(x)\n",
    "    x = Dense(500, activation='relu')(x)\n",
    "    x = Dense(30, activation='relu')(x)\n",
    "    mu, sigma = GaussianLayer(num_classes, name='main_output')(x)\n",
    "    model = Model(inputs, mu)\n",
    "    model.compile(loss=custom_loss(sigma), optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size = 10)\n",
    "    layer_name = 'main_output' # Where to extract the output from\n",
    "    get_intermediate = K.function(inputs=[model.input], outputs=model.get_layer(layer_name).output)\n",
    "    return get_intermediate\n",
    "\n",
    "\n",
    "\n",
    "prediction_fns = []\n",
    "for i in range(10):\n",
    "    prediction_fns.append(create_trained_network(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, sigmas = [], []\n",
    "for i in range(10):\n",
    "    pred = prediction_fns[i](np.array([X_test[0]]))[0]\n",
    "    sigma = prediction_fns[i](np.array([X_test[0]]))[1]\n",
    "    \n",
    "    preds.append(pred)\n",
    "    sigmas.append(sigma)\n",
    "    \n",
    "preds = np.array(preds)\n",
    "sigmas = np.array(sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trained_network_with_adv(X_train, y_train):\n",
    "    input_shape=(X_train.shape[1], 1)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    outputs = Input(shape=input_shape) \n",
    "    x = Conv1D(filters=10, kernel_size=3, activation='relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size=50)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1500, activation='relu')(x)\n",
    "    x = Dense(500, activation='relu')(x)\n",
    "    x = Dense(30, activation='relu')(x)\n",
    "    mu, sigma = GaussianLayer(num_classes, name='main_output')(x)\n",
    "    model = Model(inputs, mu)\n",
    "    model.compile(loss=custom_loss(sigma), optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size = 10)\n",
    "    \n",
    "    def gaussian_loss(y_true, y_pred, sigma):\n",
    "        \"\"\"\n",
    "        Util function used to derive gradients w.r.t. to input data (for adversarial examples generation)\n",
    "        \"\"\"\n",
    "        return math.reduce_mean(0.5*math.log(sigma) + 0.5*math.divide(math.square(y_true - y_pred), sigma)) + 1e-6\n",
    "    \n",
    "    \n",
    "    #### ADVERSARIAL TRAINING EXAMPLES GENERATION\n",
    "    loss_calc = gaussian_loss(outputs, mu, sigma)\n",
    "    \n",
    "    loss_gradients = tf.gradients(loss_calc, inputs)\n",
    "    gr_sign = tf.sign(loss_gradients)\n",
    "    adversarial_input_data = tf.add(inputs, 0.4 * gr_sign)\n",
    "    \n",
    "    print(adversarial_input_data[0])\n",
    "    ####\n",
    "    sess = tf.compat.v1.Session()\n",
    "    init_op = tf.compat.v1.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    adversarial_input_data = sess.run(adversarial_input_data[0], feed_dict={inputs: X_train, outputs: y_train})[0]\n",
    "    \n",
    "    augmented_train_x = np.concatenate([X_train, adversarial_input_data.reshape(X_train.shape[0], 1)])\n",
    "    augmented_train_y = np.concatenate([y_train, y_train])\n",
    "    \n",
    "    model.fit(augmented_train_x, augmented_train_y, epochs=1, verbose=0)\n",
    "    \n",
    "    get_intermediate = K.function(inputs=[model.input], outputs=model.get_layer(layer_name).output)\n",
    "    \n",
    "    return get_intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_68 (InputLayer)        [(None, 25000, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 24998, 10)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 499, 10)           0         \n",
      "_________________________________________________________________\n",
      "flatten_51 (Flatten)         (None, 4990)              0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 1500)              7486500   \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 500)               750500    \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "main_output (GaussianLayer)  [(None, 5), (None, 5)]    310       \n",
      "=================================================================\n",
      "Total params: 8,252,380\n",
      "Trainable params: 8,252,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 5)\n",
      "Train on 2322 samples\n",
      "2322/2322 [==============================] - 11s 5ms/sample - loss: -0.3808\n",
      "Tensor(\"strided_slice_1:0\", shape=(None, 25000, 1), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (2322, 5) for Tensor 'input_93:0', which has shape '(None, 25000, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-366-554bddba0b6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprediction_fns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprediction_fns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_trained_network_with_adv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-365-90048dcbaf73>\u001b[0m in \u001b[0;36mcreate_trained_network_with_adv\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0madversarial_input_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madversarial_input_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0maugmented_train_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madversarial_input_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1168\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (2322, 5) for Tensor 'input_93:0', which has shape '(None, 25000, 1)'"
     ]
    }
   ],
   "source": [
    "prediction_fns = []\n",
    "for i in range(2):\n",
    "    prediction_fns.append(create_trained_network_with_adv(X_train, y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
