{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "molecular-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.insert(1, module_path + '/src')\n",
    "\n",
    "import utility\n",
    "target_rate = 44100\n",
    "import librosa\n",
    "import sktime\n",
    "from sktime.utils.data_io import load_from_tsfile_to_dataframe\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "considerable-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_path = module_path + '/data/crackleWheeze/none/'\n",
    "crackle_path = module_path + '/data/crackleWheeze/crackle/'\n",
    "both_path = module_path + '/data/crackleWheeze/both/'\n",
    "wheeze_path = module_path + '/data/crackleWheeze/wheeze/'\n",
    "\n",
    "\n",
    "none = [file_name for file_name in os.listdir(none_path) if '.wav' in file_name]\n",
    "crackle = [file_name for file_name in os.listdir(crackle_path) if '.wav' in file_name]\n",
    "wheeze = [file_name for file_name in os.listdir(wheeze_path) if '.wav' in file_name]\n",
    "both= [file_name for file_name in os.listdir(both_path) if '.wav' in file_name]\n",
    "\n",
    "\n",
    "class_lists = {'crackle' : crackle,\n",
    "    'wheeze': wheeze,\n",
    "    'none': none, \n",
    "    'both': both\n",
    "}\n",
    "\n",
    "class_paths = {'crackle' : crackle_path,\n",
    "    'wheeze': wheeze_path,\n",
    "    'none': none_path, \n",
    "    'both': both_path\n",
    "}\n",
    "\n",
    "frame_len = round(4000*0.001)\n",
    "hop_len = ceil(frame_len/1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-guyana",
   "metadata": {},
   "source": [
    "# Creating the .ts file for the four class classification problem\n",
    "\n",
    "\n",
    "@problemName <problem name>\n",
    "@timeStamps <true/false>\n",
    "@univariate <true/false>\n",
    "@classLabel <true/false> <space delimited list of possible class values>\n",
    "@data\n",
    "    \n",
    "classes: \n",
    "   0: crackle\n",
    "   1: wheeze\n",
    "   2: none \n",
    "   3: both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "artificial-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_class(writer, class_list, class_name, class_path, fixed= True, fixed_len = 2000):\n",
    "    classes = {\n",
    "    'crackle': '0',\n",
    "    'wheeze': '1',\n",
    "    'none': '2',\n",
    "    'both': '3'\n",
    "    }\n",
    "    classes_2_class = {\n",
    "    'crackle': '0',\n",
    "    'wheeze': '1',\n",
    "    'none': '1',\n",
    "    'both': '0'\n",
    "    }\n",
    "    for name in class_list: \n",
    "        audio_file = class_path + name\n",
    "        sr, audio = utility.read_wav_file(audio_file, target_rate)\n",
    "        audio = utility.denoise_audio(audio)\n",
    "        audio, sr = utility.downsample(audio, sr, 4000)\n",
    "\n",
    "        rms_new = librosa.feature.rms(audio, frame_length = frame_len, hop_length = hop_len)[0]\n",
    "        \n",
    "        if fixed: \n",
    "            if len(rms_new) > fixed_len:\n",
    "                    rms_new = rms_new[0:fixed_len]\n",
    "            df_new = np.zeros(fixed_len)\n",
    "            df_new[0:len(rms_new)] = rms_new\n",
    "            new_row = str(list(df_new))[1:-1].replace(' ', '') + ':' + classes[class_name] + '\\n'\n",
    "        else: \n",
    "            new_row = str(list(rms_new))[1:-1].replace(' ', '') + ':' + classes[class_name] + '\\n'\n",
    "        writer.write(new_row)\n",
    "\n",
    "def write_ts(filename, fixed = True, fixed_len = 2000):\n",
    "    w = open(filename, 'w+')\n",
    "    row = w.read()\n",
    "\n",
    "    w.write('@problemName LungSounds \\n')\n",
    "    w.write('@timeStamps false \\n')\n",
    "    w.write('@missing false \\n')\n",
    "    w.write('@univariate true \\n')\n",
    "    if fixed: \n",
    "        w.write('@equalLength true \\n')\n",
    "        w.write(f'@seriesLength {str(fixed_len)} \\n')\n",
    "    else:\n",
    "        w.write('@equalLength false \\n')\n",
    "    w.write('@classLabel true crackle wheeze none both \\n')\n",
    "    w.write('@data \\n')\n",
    "\n",
    "    for class_name, class_list in class_lists.items():\n",
    "        if fixed:\n",
    "            write_class(w , class_list, class_name, class_paths[class_name], True, fixed_len)\n",
    "        else: \n",
    "            write_class(w , class_list, class_name, class_paths[class_name], False)\n",
    "    #os.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "possible-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_ts(module_path + '/data/ts_files/crackleWheeze.ts', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-portuguese",
   "metadata": {},
   "source": [
    "# Creating the .ts files for the two class classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "coupled-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_class2(writer, class_list, class_name, class_path, fixed= True, fixed_len = 2000):\n",
    "    classes = {\n",
    "    'crackle': '0',\n",
    "    'wheeze': '1',\n",
    "    'none': '1',\n",
    "    'both': '0'\n",
    "    }\n",
    "    for name in class_list: \n",
    "        audio_file = class_path + name\n",
    "        sr, audio = utility.read_wav_file(audio_file, target_rate)\n",
    "        audio = utility.denoise_audio(audio)\n",
    "        audio, sr = utility.downsample(audio, sr, 4000)\n",
    "\n",
    "        rms_new = librosa.feature.rms(audio, frame_length = frame_len, hop_length = hop_len)[0]\n",
    "        \n",
    "        if fixed: \n",
    "            if len(rms_new) > fixed_len:\n",
    "                    rms_new = rms_new[0:fixed_len]\n",
    "            df_new = np.zeros(fixed_len)\n",
    "            df_new[0:len(rms_new)] = rms_new\n",
    "            new_row = str(list(df_new))[1:-1].replace(' ', '') + ':' + classes[class_name] + '\\n'\n",
    "        else: \n",
    "            new_row = str(list(rms_new))[1:-1].replace(' ', '') + ':' + classes[class_name] + '\\n'\n",
    "        writer.write(new_row)\n",
    "\n",
    "def write_ts2(filename, fixed = True, fixed_len = 2000):\n",
    "    w = open(filename, 'w+')\n",
    "    row = w.read()\n",
    "\n",
    "    w.write('@problemName LungSounds \\n')\n",
    "    w.write('@timeStamps false \\n')\n",
    "    w.write('@missing false \\n')\n",
    "    w.write('@univariate true \\n')\n",
    "    if fixed: \n",
    "        w.write('@equalLength true \\n')\n",
    "        w.write(f'@seriesLength {str(fixed_len)} \\n')\n",
    "    else:\n",
    "        w.write('@equalLength false \\n')\n",
    "    w.write('@classLabel true crackle no_crackle \\n')\n",
    "    w.write('@data \\n')\n",
    "\n",
    "    for class_name, class_list in class_lists.items():\n",
    "        if fixed:\n",
    "            write_class2(w , class_list, class_name, class_paths[class_name], True, fixed_len)\n",
    "        else: \n",
    "            write_class2(w , class_list, class_name, class_paths[class_name], False)\n",
    "    #os.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "suspected-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ts2(module_path + '/data/ts_files/crackleNoCrackleSamleLength3000.ts', True, 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-atmosphere",
   "metadata": {},
   "source": [
    "# Classification using sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "seeing-biography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1'] [1777 3396]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sktime.classification.compose import TimeSeriesForestClassifier\n",
    "\n",
    "import time as time\n",
    "\n",
    "\n",
    "\n",
    "X, y = load_from_tsfile_to_dataframe(module_path + '/data/ts_files/crackleNoCrackleSamleLength3000.ts')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "labels, counts = np.unique(y_train, return_counts=True)\n",
    "print(labels, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-baseball",
   "metadata": {},
   "source": [
    "# Interval Based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-elite",
   "metadata": {},
   "source": [
    "## Testing out time series forest classifier (TSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "superb-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2000 = y_pred  # time 352.05756402015686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "radical-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1725 points : 566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.34       263\n",
      "           1       0.90      0.69      0.78      1462\n",
      "\n",
      "    accuracy                           0.67      1725\n",
      "   macro avg       0.57      0.62      0.56      1725\n",
      "weighted avg       0.80      0.67      0.71      1725\n",
      "\n",
      "Time:  542.2675955295563\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tsf = TimeSeriesForestClassifier()\n",
    "tsf.fit(X_train, y_train)\n",
    "tsf_y_pred = tsf.predict(X_test)\n",
    "print(f'Number of mislabeled points out of a total {X_test.shape[0]} points : {(y_test != tsf_y_pred).sum()}')\n",
    "print(classification_report(tsf_y_pred, y_test))\n",
    "end = time.time()\n",
    "print('Time: ', str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-drive",
   "metadata": {},
   "source": [
    "## Test of interval based classifier (RISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "opponent-university",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5136231884057971"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.classification.interval_based import RandomIntervalSpectralForest\n",
    "\n",
    "rise = RandomIntervalSpectralForest(n_estimators=10)\n",
    "rise.fit(X_train, y_train)\n",
    "rise.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-blocking",
   "metadata": {},
   "source": [
    "# Dictionary based "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-export",
   "metadata": {},
   "source": [
    "## BOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.dictionary_based._boss import BOSSEnsemble\n",
    "\n",
    "start = time.time()\n",
    "boss = BOSSEnsemble()\n",
    "boss.fit(X_train, y_train)\n",
    "boss_y_pred = boss.predict(X_test)\n",
    "print(f'Number of mislabeled points out of a total {X_test.shape[0]} points : {(y_test != boss_y_pred).sum()}')\n",
    "print(classification_report(boss_y_pred, y_test))\n",
    "\n",
    "end = time.time()\n",
    "print('Time: ', str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-livestock",
   "metadata": {},
   "source": [
    "## cBOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.dictionary_based import ContractableBOSS\n",
    "from time import time \n",
    "\n",
    "\n",
    "indices = np.random.RandomState(0).permutation(10)\n",
    "\n",
    "cboss = ContractableBOSS(\n",
    "    n_parameter_samples=50, max_ensemble_size=10, random_state=0\n",
    ")\n",
    "\n",
    "start = time()\n",
    "cboss.fit(X_train, y_train)\n",
    "end = time()\n",
    "score_cboss = cboss.score(X_test.iloc[indices], y_test[indices])\n",
    "\n",
    "print('Time used to train: ', str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-beads",
   "metadata": {},
   "source": [
    "# Shapelet Based\n",
    "\n",
    "## MR SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.shapelet_based import MrSEQLClassifier\n",
    "from sktime.classification.shapelet_based import ROCKETClassifier\n",
    "from numpy import testing\n",
    "\n",
    "sax_clf = MrSEQLClassifier(seql_mode='fs', symrep=['sax'])\n",
    "sfa_clf = MrSEQLClassifier(seql_mode='fs', symrep=['sfa'])\n",
    "ss_clf = MrSEQLClassifier(seql_mode='fs', symrep=['sax', 'sfa'])\n",
    "\n",
    "# fit training data\n",
    "sax_clf.fit(X_train, y_train)\n",
    "sfa_clf.fit(X_train, y_train)\n",
    "ss_clf.fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "sax_predicted = sax_clf.predict(X_test)\n",
    "sfa_predicted = sfa_clf.predict(X_test)\n",
    "ss_predicted = ss_clf.predict(X_test)\n",
    "\n",
    "# test feature space dimension\n",
    "# the multi-domain classifier (ss_clf) should produce as many features\n",
    "# as the others (sax_clf and sfa_clf) combine\n",
    "np.testing.assert_equal(ss_clf.ots_clf.coef_.shape[1],\n",
    "                        sfa_clf.ots_clf.coef_.shape[1] +\n",
    "                        sax_clf.ots_clf.coef_.shape[1])\n",
    "\n",
    "# test number of correct predictions\n",
    "np.testing.assert_equal((sax_predicted == y_test).sum(), 148)\n",
    "np.testing.assert_equal((sfa_predicted == y_test).sum(), 150)\n",
    "np.testing.assert_equal((ss_predicted == y_test).sum(), 150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-snapshot",
   "metadata": {},
   "source": [
    "## ROCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.RandomState(0).permutation(100)\n",
    "\n",
    "# train ROCKET\n",
    "rocket = ROCKETClassifier(num_kernels=1000, random_state=0)\n",
    "rocket.fit(X_train, y_train)\n",
    "\n",
    "score_rocket = rocket.score(X_test.iloc[indices], y_test[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-gibraltar",
   "metadata": {},
   "source": [
    "# Hybrid\n",
    "\n",
    "## Catch22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.hybrid._catch22_forest_classifier import (\n",
    "    Catch22ForestClassifier,\n",
    ")\n",
    "\n",
    "indices = np.random.RandomState(0).permutation(20)\n",
    "\n",
    "c22f = Catch22ForestClassifier(random_state=0)\n",
    "c22f.fit(X_train.iloc[indices], y_train[indices])\n",
    "\n",
    "score_c22f = c22f.score(X_test.iloc[indices], y_test[indices])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
