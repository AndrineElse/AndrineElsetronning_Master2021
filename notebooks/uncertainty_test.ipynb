{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With inspiration from : https://towardsdatascience.com/my-deep-learning-model-says-sorry-i-dont-know-the-answer-that-s-absolutely-ok-50ffa562cb0b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "sys.path.insert(1, module_path + '/src')\n",
    "import audio_time_series_classification as preproject\n",
    "import utility\n",
    "\n",
    "sys.path.insert(1, module_path + '/src/models/')\n",
    "import helper\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sktime.utils.data_io import load_from_tsfile_to_dataframe\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sktime.utils.data_processing import from_nested_to_2d_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sktime.utils.data_io import load_from_tsfile_to_dataframe\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "figure_path = module_path + '/figures/'\n",
    "\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, ZeroPadding1D, MaxPooling1D, BatchNormalization, Activation, Dropout, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train_o = load_from_tsfile_to_dataframe(module_path + f'/features/extracted_ts_files/UiT_allLabels_15s_TRAIN.ts')\n",
    "X_test, y_test_o = load_from_tsfile_to_dataframe(module_path + f'/features/extracted_ts_files/UiT_allLabels_15s_TEST.ts')\n",
    "X_val, y_val_o = load_from_tsfile_to_dataframe(module_path + f'/features/extracted_ts_files/UiT_allLabels_15s_VAL.ts')\n",
    "\n",
    "X_train, X_test, X_val = from_nested_to_2d_array(X_train), from_nested_to_2d_array(X_test), from_nested_to_2d_array(X_val)\n",
    "\n",
    "cols = np.arange(len(X_test.columns))\n",
    "X_train.columns, X_test.columns, X_val.columns = cols, cols, cols\n",
    "\n",
    "y_train_o, y_test_o, y_val_o = pd.Series(y_train_o), pd.Series(y_test_o), pd.Series(y_val_o)\n",
    "\n",
    "scaler = MinMaxScaler() \n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train)) \n",
    "X_val = pd.DataFrame(scaler.transform(X_val)) \n",
    "X_test = pd.DataFrame(scaler.transform(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = y_train_o.copy(deep = True)\n",
    "\n",
    "y_train_new[y_train_new == 'exp_wheeze'] = 'wheeze'\n",
    "y_train_new[y_train_new == 'insp_wheeze'] = 'wheeze'\n",
    "y_train_new[y_train_new == 'exp_crackle'] = 'crackle'\n",
    "y_train_new[y_train_new == 'insp_crackle'] = 'crackle'\n",
    "\n",
    "y_test_new = y_test_o.copy(deep = True)\n",
    "\n",
    "y_test_new[y_test_new == 'exp_wheeze'] = 'wheeze'\n",
    "y_test_new[y_test_new == 'insp_wheeze'] = 'wheeze'\n",
    "y_test_new[y_test_new == 'exp_crackle'] = 'crackle'\n",
    "y_test_new[y_test_new == 'insp_crackle'] = 'crackle'\n",
    "\n",
    "y_val_new = y_val_o.copy(deep = True)\n",
    "\n",
    "y_val_new[y_val_new == 'exp_wheeze'] = 'wheeze'\n",
    "y_val_new[y_val_new == 'insp_wheeze'] = 'wheeze'\n",
    "y_val_new[y_val_new == 'exp_crackle'] = 'crackle'\n",
    "y_val_new[y_val_new == 'insp_crackle'] = 'crackle'\n",
    "\n",
    "indices_1 = np.where(y_train_new == 'normal')[0]\n",
    "indices_2 = np.where(y_train_new == 'wheeze')[0]\n",
    "indices_3 = np.where(y_train_new == 'crackle')[0]\n",
    "#indices_train = np.concatenate((indices_2, indices_3))\n",
    "indices_train = np.concatenate((indices_1[:250], indices_2, indices_3))\n",
    "\n",
    "indices_1 = np.where(y_test_new == 'normal')[0]\n",
    "indices_2 = np.where(y_test_new == 'wheeze')[0]\n",
    "indices_3 = np.where(y_test_new == 'crackle')[0]\n",
    "#indices_test = np.concatenate((indices_2, indices_3))\n",
    "indices_test = np.concatenate((indices_1, indices_2, indices_3))\n",
    "\n",
    "indices_1 = np.where(y_val_new == 'normal')[0]\n",
    "indices_2 = np.where(y_val_new == 'wheeze')[0]\n",
    "indices_3 = np.where(y_val_new == 'crackle')[0]\n",
    "#indices_val = np.concatenate((indices_2, indices_3))\n",
    "indices_val = np.concatenate((indices_1, indices_2, indices_3))\n",
    "\n",
    "y_train = y_train_new[indices_train]\n",
    "y_test = y_test_new[indices_test]\n",
    "y_val = y_val_new[indices_val]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(y_train_new[indices_train])\n",
    "num_classes = len(le.classes_)\n",
    "y_train = le.transform(y_train_new[indices_train])\n",
    "y_test = le.transform(y_test_new[indices_test])\n",
    "y_val = le.transform(y_val_new[indices_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(BatchNormalization()) \n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(BatchNormalization()) \n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(BatchNormalization()) \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 218)]             0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               21900     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 27,482\n",
      "Trainable params: 27,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "here\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 218)]             0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 100)               21900     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 27,482\n",
      "Trainable params: 27,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# function for creating a fully connected neural network of any architecture\n",
    "# the number of neurons in each layer is defined by layers_shape\n",
    "# the droupout_proba indicates if dropout layers should be added\n",
    "def architecture(layers_shape, input_dim, output_dim, dropout_proba, reg, act='relu', verbose=False):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    hidden = Dense(layers_shape[0], activation=act,\n",
    "                   kernel_regularizer=l2(reg))(inputs)\n",
    "    for i in range(len(layers_shape)-1):\n",
    "        if dropout_proba > 0:\n",
    "            hidden = Dropout(dropout_proba)(hidden, training=True)\n",
    "        hidden = Dense(layers_shape[i+1], activation=act, kernel_regularizer=l2(reg))(hidden)\n",
    "    if dropout_proba > 0:\n",
    "        hidden = Dropout(dropout_proba)(hidden, training=True)\n",
    "    outputs = Dense(output_dim, kernel_regularizer=l2(reg))(hidden) \n",
    "    model = Model(inputs, outputs)\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    return model\n",
    "  \n",
    "model_without_dropout = architecture(layers_shape=[100, 50, 10], input_dim= 218, output_dim=2, \n",
    "                                     dropout_proba=0, reg=0, act='relu', verbose=1)\n",
    "\n",
    "model_with_dropout = architecture(layers_shape=[100, 50, 10], input_dim= 218, output_dim=2, \n",
    "                                  dropout_proba=0.05, reg=0.00475, act='relu', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   5   19   30   65   90   93  113  165  169  183  192  196  221  261\n",
      "  281  296  310  317  386  396  398  412  427  429  438  453  494  508\n",
      "  565  586  609  628  653  660  670  676  703  708  712  724  735  765\n",
      "  778  816  819  831  849  857  867  905  926  942  943  975  977  979\n",
      "  992  997 1030 1032 1041 1047 1056 1082 1096 1111 1117 1155 1167 1178\n",
      " 1180 1214 1215 1231 1239 1253 1263 1271 1301 1303 1338 1341 1348]\n",
      "99\n",
      "[   8   12   32   36   41   42   50   53   60   75   90  108  122  123\n",
      "  140  161  167  177  179  192  195  227  237  242  265  270  281  294\n",
      "  303  305  312  315  330  332  336  343  344  356  361  372  376  377\n",
      "  393  409  413  414  421  423  445  456  462  463  480  481  485  498\n",
      "  503  508  528  530  532  533  554  562  568  580  615  621  652  663\n",
      "  672  675  686  690  695  703  712  714  724  728  739  740  793  804\n",
      "  805  813  819  831  845  847  868  884  890  899  901  921  943  944\n",
      "  965  970  978  982  986  992  993  995 1000 1007 1009 1021 1029 1034\n",
      " 1038 1051 1058 1079 1083 1086 1089 1098 1116 1117 1122 1124 1130 1137\n",
      " 1140 1155 1169 1170 1174 1185 1188 1235 1242 1257 1268 1289 1295 1307\n",
      " 1309 1312 1318 1319 1323 1333 1341 1364 1366 1379]\n",
      "140\n",
      "[]\n",
      "0\n",
      "[  12   50  133  143  164  197  263  265  280  287  314  320  370  468\n",
      "  490  495  527  572  619  624  627  633  652  678  681  690  703  732\n",
      "  793  794  825  833  834  842  905  924  943  946  951  966  973  983\n",
      " 1000 1036 1047 1072 1087 1141 1153 1190 1253 1257 1259 1278 1290 1323\n",
      " 1348 1367 1377]\n",
      "100\n",
      "[  20   36   62   70   87  108  130  133  137  144  156  159  252  271\n",
      "  281  283  300  343  358  389  393  394  415  442  459  494  571  601\n",
      "  603  655  684  699  711  731  747  752  766  796  802  806  808  818\n",
      "  820  885  924  933  940  964  975  980  988 1003 1005 1033 1041 1063\n",
      " 1066 1087 1123 1148 1153 1237 1271 1287 1310 1315 1329 1335 1375]\n",
      "18\n",
      "[  18   50   52  192  206  217  224  228  265  401  473  503  552  557\n",
      "  562  577  633  654  689  742  756  825  850  855  896  905  932  942\n",
      "  951  966  985 1034 1036 1047 1102 1154 1185 1289 1311 1367 1377]\n",
      "27\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[  57   78  142  148  166  188  225  227  282  315  325  331  347  355\n",
      "  386  500  517  523  531  623  641  642  652  656  665  685  690  703\n",
      "  734  741  744  764  812  869  871  873  884  885  922  947  950  959\n",
      "  987 1015 1048 1059 1083 1088 1117 1126 1149 1153 1154 1174 1182 1251\n",
      " 1259 1341 1363]\n",
      "56\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[  16   57   77   92   93  148  159  166  178  188  194  210  267  282\n",
      "  312  347  355  386  460  531  570  580  640  656  665  684  685  734\n",
      "  764  771  794  812  857  871  885  900  919  950  964  966  975 1015\n",
      " 1024 1029 1048 1056 1086 1093 1108 1149 1154 1156 1157 1259 1290 1299\n",
      " 1302 1343 1363]\n",
      "87\n",
      "[]\n",
      "0\n",
      "[ 121  143  206  303  332  336  356  361  376  416  462  498  503  610\n",
      "  619  731  833  855  895  899  951  983 1000 1034 1072 1169 1171 1199\n",
      " 1242 1256 1340]\n",
      "67\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[ 118  143  171  179  191  204  228  303  332  336  344  376  395  400\n",
      "  410  462  473  480  484  498  503  557  562  621  640  650  657  700\n",
      "  731  732  733  740  895  897  982 1051 1082 1130 1169 1171 1229 1243\n",
      " 1248 1256 1270 1323 1328 1333 1339]\n",
      "32\n",
      "[]\n",
      "0\n",
      "[  86  171  179  191  193  228  269  344  395  400  462  480  485  498\n",
      "  503  557  562  610  637  733  742  833  895  932  962  982 1098 1106\n",
      " 1112 1161 1169 1185 1196 1229 1312 1323 1377]\n",
      "24\n",
      "[  86  171  193  228  395  462  480  498  503  528  637  833 1098 1161\n",
      " 1169 1185 1312 1377]\n",
      "35\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[  34   35   50   54   59   86  123  171  177  188  195  206  254  269\n",
      "  273  282  316  330  332  352  395  400  410  462  480  485  498  503\n",
      "  519  549  557  562  583  612  615  623  624  645  681  690  708  733\n",
      "  741  742  754  786  792  796  833  841  845  850  856  872  879  895\n",
      "  897  932  983 1021 1047 1051 1079 1080 1098 1106 1112 1124 1127 1161\n",
      " 1169 1170 1171 1185 1188 1199 1282 1289 1312 1323 1337 1361 1366 1377]\n",
      "20\n",
      "[  35   36   38   50   74   90  108  143  175  188  197  282  303  330\n",
      "  332  336  345  384  393  401  413  456  462  473  480  498  503  528\n",
      "  531  557  562  583  615  623  645  681  690  699  709  727  733  770\n",
      "  786  837  842  845  850  872  879  895  897  905  983 1079 1082 1112\n",
      " 1124 1127 1130 1146 1169 1188 1199 1243 1256 1259 1282 1302 1323 1328\n",
      " 1333 1337 1366]\n",
      "31\n",
      "[]\n",
      "0\n",
      "[  36   50   51   62   90  108  143  146  150  171  173  175  197  219\n",
      "  255  291  303  307  332  358  371  393  395  413  421  462  473  480\n",
      "  498  503  510  528  538  552  556  557  562  595  600  634  640  654\n",
      "  672  686  700  707  722  727  732  733  740  770  834  895  905  916\n",
      "  936  966  995 1060 1073 1082 1085 1104 1107 1112 1130 1146 1148 1157\n",
      " 1169 1171 1173 1195 1221 1229 1233 1253 1256 1285 1290 1299 1302 1315\n",
      " 1323 1328 1333 1379]\n",
      "23\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[  38   54   74   86  142  171  177  179  188  191  193  195  228  269\n",
      "  282  331  387  395  401  462  480  498  503  528  553  557  562  583\n",
      "  610  612  615  623  637  645  690  709  733  742  754  786  792  796\n",
      "  809  833  841  845  850  872  879  895  932  983 1054 1059 1079 1098\n",
      " 1112 1124 1127 1161 1169 1174 1185 1188 1196 1229 1259 1312 1323 1337\n",
      " 1366 1377]\n",
      "35\n",
      "[  38   54   74   86  142  171  177  179  188  191  193  195  228  269\n",
      "  282  331  352  387  395  401  462  480  498  503  553  557  562  583\n",
      "  612  623  637  645  690  709  733  742  754  786  792  809  833  841\n",
      "  845  850  872  879  895  932  983 1054 1059 1079 1098 1112 1124 1127\n",
      " 1161 1169 1174 1185 1188 1196 1229 1245 1259 1312 1323 1337 1366 1377]\n",
      "38\n",
      "[  86  171  193  228  395  462  480  498  503  528  637  833 1098 1161\n",
      " 1169 1185 1312 1377]\n",
      "35\n",
      "[  35   36   90  171  195  303  393  462  503  557  562  727  837 1079\n",
      " 1112 1124 1130 1188 1328 1366]\n",
      "50\n",
      "[  34   50   54   61   62   86  146  171  179  193  228  254  269  273\n",
      "  307  332  395  410  462  480  498  503  528  552  557  562  627  634\n",
      "  640  686  707  732  733  740  742  770  833  895  905  916  932  936\n",
      " 1054 1073 1085 1087 1098 1107 1112 1157 1161 1169 1170 1185 1196 1199\n",
      " 1229 1233 1290 1299 1312 1315 1323 1339 1377]\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn import metrics\n",
    "\n",
    "from fylearn.nfpc import FuzzyPatternClassifier\n",
    "from fylearn.fpt import FuzzyPatternTreeTopDownClassifier\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "clf = FuzzyPatternTreeTopDownClassifier()\n",
    "\n",
    "auc = []\n",
    "ignorance = []\n",
    "conflict = []\n",
    "\n",
    "indices_0 = np.where(y_train.astype(int) == 0)[0]\n",
    "indices_1 = np.where(y_train.astype(int) == 1)[0]\n",
    "indices = np.concatenate((indices_0[0:1929], indices_1))\n",
    "\n",
    "\n",
    "for i in range(100, len(indices), 100):\n",
    "\n",
    "    p = indices.copy()\n",
    "    random.shuffle(p)\n",
    "    indices_2 = p[0:i]\n",
    "    \n",
    "\n",
    "    clf.fit(X_train.iloc[indices_2], y_train.iloc[indices_2])\n",
    "\n",
    "    pred, t = clf.predict(X_test)\n",
    "    \n",
    "    auc_score = metrics.roc_auc_score(y_test, pred)\n",
    "    \n",
    "    ig = np.where((((t< 0.45)[: , 0]) & ((t< 0.45)[: , 1])) == True)[0]\n",
    "    ignorant_indices = len(ig)\n",
    "    print(ig)\n",
    "\n",
    "    conf = np.where((((t> 0.55)[: , 0]) & ((t> 0.55)[: , 1])) == True)[0]\n",
    "    conflict_indices = len(conf)\n",
    "    print(conflict_indices)\n",
    "    \n",
    "    conflict.append(conflict_indices)\n",
    "    ignorance.append(ignorant_indices)\n",
    "    auc.append(auc_score)\n",
    "    #break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
